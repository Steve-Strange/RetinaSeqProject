{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:27.187106Z",
     "iopub.status.busy": "2025-12-26T10:17:27.186304Z",
     "iopub.status.idle": "2025-12-26T10:17:38.866947Z",
     "shell.execute_reply": "2025-12-26T10:17:38.866281Z",
     "shell.execute_reply.started": "2025-12-26T10:17:27.187068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangziteng/miniconda3/envs/pampc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20 - 20\n",
      "Test: 20 - 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.29it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 55.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"config.py\"):\n",
    "    print(\"Warning: Found 'config.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "if os.path.exists(\"torch.py\"):\n",
    "    print(\"Warning: Found 'torch.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "\n",
    "# 优先导入 torch\n",
    "import torch\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast, RandomCrop, RandomRotate90, RandomGridShuffle\n",
    "\n",
    "\"\"\" Create a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "'''加载数据：原图+标签'''\n",
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "'''\n",
    "增强数据\n",
    "对图像及其对应mask数据增强\n",
    "'''\n",
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    size = (560, 560)\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(os.sep)[-1].split(\".\")[0]\n",
    "        \n",
    "        \"\"\" Reading image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "\n",
    "        if x is None or y is None:\n",
    "            print(f\"Error reading image or mask for {name}\")\n",
    "            continue\n",
    "\n",
    "        if augment == True:\n",
    "            transformations = [\n",
    "                HorizontalFlip(p=1.0),\n",
    "                VerticalFlip(p=1.0),\n",
    "                Rotate(limit=45, p=1.0),\n",
    "                RandomBrightnessContrast(p=0.6),\n",
    "                RandomCrop(300, 300, p=0.8),\n",
    "                RandomRotate90(p=1.0),\n",
    "                RandomGridShuffle(p=0.7)\n",
    "            ]\n",
    "\n",
    "            augmented_images = [x]\n",
    "            augmented_masks = [y]\n",
    "\n",
    "            for aug in transformations:\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                augmented_images.append(augmented[\"image\"])\n",
    "                augmented_masks.append(augmented[\"mask\"])\n",
    "            \n",
    "            X = augmented_images\n",
    "            Y = augmented_masks\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            #将图像和掩码调整到目标大小\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            tmp_image_name = f\"{name}_{index}.png\"\n",
    "            tmp_mask_name = f\"{name}_{index}.png\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Load the data \"\"\"\n",
    "    # 修改为相对路径\n",
    "    data_path = \"data/DRIVE/\"\n",
    "    \n",
    "    if os.path.exists(data_path):\n",
    "        (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
    "\n",
    "        print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "        print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "        \"\"\" Create directories to save the augmented data \"\"\"\n",
    "        create_dir(\"working/new_data/train/image/\")\n",
    "        create_dir(\"working/new_data/train/mask/\")\n",
    "        create_dir(\"working/new_data/test/image/\")\n",
    "        create_dir(\"working/new_data/test/mask/\")\n",
    "\n",
    "        \"\"\" Data augmentation \"\"\"\n",
    "        # 取消注释以运行数据增强\n",
    "        augment_data(train_x, train_y, \"working/new_data/train/\", augment=True)\n",
    "        augment_data(test_x, test_y, \"working/new_data/test/\", augment=False)\n",
    "    else:\n",
    "        print(f\"Data path not found: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:38.868551Z",
     "iopub.status.busy": "2025-12-26T10:17:38.868200Z",
     "iopub.status.idle": "2025-12-26T10:17:40.435461Z",
     "shell.execute_reply": "2025-12-26T10:17:40.434747Z",
     "shell.execute_reply.started": "2025-12-26T10:17:38.868526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 560, 560])\n"
     ]
    }
   ],
   "source": [
    "# Model (LFA-Net)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalModulation(nn.Module):\n",
    "    def __init__(self, in_channels, gamma=2.0, alpha=0.25):\n",
    "        super(FocalModulation, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.gap(x)\n",
    "        max_val = self.gmp(x)\n",
    "        modulation = (max_val - mean) * self.alpha\n",
    "        modulation = self.conv(modulation)\n",
    "        modulation = self.sigmoid(modulation)\n",
    "        scaled_inputs = x * modulation\n",
    "        outputs = torch.pow(scaled_inputs, self.gamma)\n",
    "        return outputs\n",
    "\n",
    "class FocalModulationContextAggregation(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(FocalModulationContextAggregation, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, filters, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_ctx = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.focal_mod = FocalModulation(filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.relu1(self.conv1(x))\n",
    "        c2 = self.relu2(self.conv2(x))\n",
    "        \n",
    "        global_context = self.gap(c2)\n",
    "        global_context = self.sigmoid(self.conv_ctx(global_context))\n",
    "        global_context = c1 * global_context\n",
    "        \n",
    "        fm = self.focal_mod(global_context)\n",
    "        return torch.cat([c1, fm], dim=1)\n",
    "\n",
    "class VisionMambaInspired(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.1):\n",
    "        super(VisionMambaInspired, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.token_mixer = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.channel_mixer = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        shortcut = x\n",
    "        x_perm = x.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm1(x_perm).permute(0, 3, 1, 2)\n",
    "        x_tm = self.token_mixer(x_norm) + shortcut\n",
    "        \n",
    "        shortcut = x_tm\n",
    "        x_perm = x_tm.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm2(x_perm)\n",
    "        x_cm = self.channel_mixer(x_norm)\n",
    "        x_cm = x_cm.permute(0, 3, 1, 2)\n",
    "        \n",
    "        return x_cm + shortcut\n",
    "\n",
    "class LiteFusionAttention(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(LiteFusionAttention, self).__init__()\n",
    "        self.proj1 = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(filters)\n",
    "        self.conv = nn.Conv2d(filters, filters, kernel_size=3, padding=1)\n",
    "        self.fmca = FocalModulationContextAggregation(filters, filters)\n",
    "        self.proj2 = nn.Conv2d(2 * filters, filters, kernel_size=1)\n",
    "        self.vm = VisionMambaInspired(filters)\n",
    "        \n",
    "        self.res_proj = nn.Conv2d(in_channels, filters, kernel_size=1) if in_channels != filters else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = self.proj1(x)\n",
    "        \n",
    "        x_perm = input_tensor.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm(x_perm).permute(0, 3, 1, 2)\n",
    "        \n",
    "        x_conv = self.conv(x_norm)\n",
    "        x_fmca = self.fmca(x_conv)\n",
    "        x_proj = self.proj2(x_fmca)\n",
    "        \n",
    "        res = self.res_proj(x) if isinstance(self.res_proj, nn.Conv2d) else input_tensor\n",
    "        out = x_proj + res\n",
    "        \n",
    "        out = self.vm(out)\n",
    "        return out\n",
    "\n",
    "class RA_AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, k):\n",
    "        super(RA_AttentionBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.conv = nn.Conv2d(in_channels, k * n_classes, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(k * n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        f = self.relu(self.bn(self.conv(x)))\n",
    "        \n",
    "        x1 = self.gmp(f)\n",
    "        x2 = self.gap(f)\n",
    "        x_mul = x1 * x2\n",
    "        \n",
    "        x_reshape = x_mul.view(b, self.n_classes, self.k)\n",
    "        s = torch.mean(x_reshape, dim=-1, keepdim=False)\n",
    "        \n",
    "        f_perm = f.permute(0, 2, 3, 1)\n",
    "        f_reshape = f_perm.view(b, h, w, self.n_classes, self.k)\n",
    "        f_mean = torch.mean(f_reshape, dim=-1, keepdim=False)\n",
    "        \n",
    "        s_expanded = s.view(b, 1, 1, self.n_classes)\n",
    "        x_weighted = f_mean * s_expanded\n",
    "        \n",
    "        m = torch.mean(x_weighted, dim=-1, keepdim=True)\n",
    "        m = m.permute(0, 3, 1, 2)\n",
    "        \n",
    "        semantic = x * m\n",
    "        return semantic\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.5):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv3x3_dilated = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2, bias=False)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1x1(x)\n",
    "        c3 = self.conv3x3(x)\n",
    "        c3d = self.conv3x3_dilated(x)\n",
    "        out = c1 + c3 + c3d\n",
    "        out = self.leaky_relu(out)\n",
    "        return out\n",
    "\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=1, feature_scale=2, dropout=0.5):\n",
    "        super(build_unet, self).__init__()\n",
    "        filters = [int(x / feature_scale) for x in [16, 32, 64]]\n",
    "        \n",
    "        self.conv1 = ConvBlock(input_channels, filters[0], dropout)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.bn1 = nn.BatchNorm2d(filters[0])\n",
    "        \n",
    "        self.conv2 = ConvBlock(filters[0], filters[1], dropout)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.bn2 = nn.BatchNorm2d(filters[1])\n",
    "        \n",
    "        self.conv3 = ConvBlock(filters[1], filters[2], dropout)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bn3 = nn.BatchNorm2d(filters[2])\n",
    "        \n",
    "        self.lfa = LiteFusionAttention(filters[2], filters=32)\n",
    "        \n",
    "        lfa_out_channels = 32 \n",
    "        self.att1 = RA_AttentionBlock(lfa_out_channels, 1, 16)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(lfa_out_channels * 2, filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att2 = RA_AttentionBlock(filters[1], 1, 16)\n",
    "        self.dec_conv1 = nn.Conv2d(filters[1] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att3 = RA_AttentionBlock(filters[0], 1, 16)\n",
    "        self.dec_conv2 = nn.Conv2d(filters[0] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(filters[2], filters[0], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_conv3 = nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.final = nn.Conv2d(filters[0], num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.bn1(self.pool1(c1))\n",
    "        \n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.bn2(self.pool2(c2))\n",
    "        \n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.bn3(self.pool3(c3))\n",
    "        \n",
    "        lfa = self.lfa(p3)\n",
    "        \n",
    "        att1 = self.att1(lfa)\n",
    "        fused = torch.cat([att1, lfa], dim=1)\n",
    "        \n",
    "        d1 = self.up1(fused)\n",
    "        if d1.size() != c2.size():\n",
    "             d1 = F.interpolate(d1, size=c2.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        att2 = self.att2(c2)\n",
    "        d1 = torch.cat([att2, d1], dim=1)\n",
    "        d1 = self.relu1(self.dec_conv1(d1))\n",
    "        \n",
    "        d2 = self.up2(d1)\n",
    "        if d2.size() != c1.size():\n",
    "             d2 = F.interpolate(d2, size=c1.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        att3 = self.att3(c1)\n",
    "        d2 = torch.cat([att3, d2], dim=1)\n",
    "        d2 = self.relu2(self.dec_conv2(d2))\n",
    "        \n",
    "        d3 = self.up3(d2)\n",
    "        if d3.size() != x.size():\n",
    "             d3 = F.interpolate(d3, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        d3 = self.relu3(self.dec_conv3(d3))\n",
    "        \n",
    "        out = self.final(d3)\n",
    "        return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((2, 3, 560, 560))\n",
    "    f = build_unet()\n",
    "    y = f(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.437315Z",
     "iopub.status.busy": "2025-12-26T10:17:40.437071Z",
     "iopub.status.idle": "2025-12-26T10:17:40.443522Z",
     "shell.execute_reply": "2025-12-26T10:17:40.442839Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.437294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image/255.0 ## (512, 512, 3)\n",
    "        image = np.transpose(image, (2, 0, 1))  ## (3, 512, 512)\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask/255.0   ## (512, 512)\n",
    "        mask = np.expand_dims(mask, axis=0) ## (1, 512, 512)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.445318Z",
     "iopub.status.busy": "2025-12-26T10:17:40.445100Z",
     "iopub.status.idle": "2025-12-26T10:17:40.467440Z",
     "shell.execute_reply": "2025-12-26T10:17:40.466743Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.445297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.468545Z",
     "iopub.status.busy": "2025-12-26T10:17:40.468339Z",
     "iopub.status.idle": "2025-12-26T10:17:40.482989Z",
     "shell.execute_reply": "2025-12-26T10:17:40.482370Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.468525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\"\"\" Seeding the randomness. \"\"\"\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\" Create a directory. \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Calculate the time taken \"\"\"\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.483887Z",
     "iopub.status.busy": "2025-12-26T10:17:40.483664Z",
     "iopub.status.idle": "2025-12-26T10:56:04.787586Z",
     "shell.execute_reply": "2025-12-26T10:56:04.786752Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.483865Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train: 160 - Valid: 20\n",
      "\n",
      "Valid loss improved from inf to 1.5144. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.515\n",
      "\t Val. Loss: 1.514\n",
      "\n",
      "Valid loss improved from 1.5144 to 1.4883. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.492\n",
      "\t Val. Loss: 1.488\n",
      "\n",
      "Valid loss improved from 1.4883 to 1.3003. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.389\n",
      "\t Val. Loss: 1.300\n",
      "\n",
      "Valid loss improved from 1.3003 to 1.2924. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.180\n",
      "\t Val. Loss: 1.292\n",
      "\n",
      "Valid loss improved from 1.2924 to 1.2292. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.099\n",
      "\t Val. Loss: 1.229\n",
      "\n",
      "Valid loss improved from 1.2292 to 1.1944. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.068\n",
      "\t Val. Loss: 1.194\n",
      "\n",
      "Valid loss improved from 1.1944 to 1.1452. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.044\n",
      "\t Val. Loss: 1.145\n",
      "\n",
      "Valid loss improved from 1.1452 to 1.1334. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 1.021\n",
      "\t Val. Loss: 1.133\n",
      "\n",
      "Valid loss improved from 1.1334 to 1.1145. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.986\n",
      "\t Val. Loss: 1.114\n",
      "\n",
      "Valid loss improved from 1.1145 to 1.1027. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.958\n",
      "\t Val. Loss: 1.103\n",
      "\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.935\n",
      "\t Val. Loss: 1.133\n",
      "\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.913\n",
      "\t Val. Loss: 1.132\n",
      "\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.894\n",
      "\t Val. Loss: 1.125\n",
      "\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.878\n",
      "\t Val. Loss: 1.124\n",
      "\n",
      "Valid loss improved from 1.1027 to 1.0972. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.865\n",
      "\t Val. Loss: 1.097\n",
      "\n",
      "Valid loss improved from 1.0972 to 1.0251. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.851\n",
      "\t Val. Loss: 1.025\n",
      "\n",
      "Valid loss improved from 1.0251 to 0.9866. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.838\n",
      "\t Val. Loss: 0.987\n",
      "\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.819\n",
      "\t Val. Loss: 1.025\n",
      "\n",
      "Valid loss improved from 0.9866 to 0.8856. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.780\n",
      "\t Val. Loss: 0.886\n",
      "\n",
      "Valid loss improved from 0.8856 to 0.8009. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.724\n",
      "\t Val. Loss: 0.801\n",
      "\n",
      "Valid loss improved from 0.8009 to 0.7806. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.703\n",
      "\t Val. Loss: 0.781\n",
      "\n",
      "Valid loss improved from 0.7806 to 0.7354. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.674\n",
      "\t Val. Loss: 0.735\n",
      "\n",
      "Valid loss improved from 0.7354 to 0.6728. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.662\n",
      "\t Val. Loss: 0.673\n",
      "\n",
      "Valid loss improved from 0.6728 to 0.6419. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.649\n",
      "\t Val. Loss: 0.642\n",
      "\n",
      "Valid loss improved from 0.6419 to 0.6250. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.639\n",
      "\t Val. Loss: 0.625\n",
      "\n",
      "Valid loss improved from 0.6250 to 0.6036. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.625\n",
      "\t Val. Loss: 0.604\n",
      "\n",
      "Valid loss improved from 0.6036 to 0.5992. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 27 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.616\n",
      "\t Val. Loss: 0.599\n",
      "\n",
      "Valid loss improved from 0.5992 to 0.5848. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 28 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.606\n",
      "\t Val. Loss: 0.585\n",
      "\n",
      "Valid loss improved from 0.5848 to 0.5828. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 29 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.593\n",
      "\t Val. Loss: 0.583\n",
      "\n",
      "Valid loss improved from 0.5828 to 0.5664. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 30 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.589\n",
      "\t Val. Loss: 0.566\n",
      "\n",
      "Valid loss improved from 0.5664 to 0.5594. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 31 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.581\n",
      "\t Val. Loss: 0.559\n",
      "\n",
      "Valid loss improved from 0.5594 to 0.5585. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 32 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.571\n",
      "\t Val. Loss: 0.559\n",
      "\n",
      "Valid loss improved from 0.5585 to 0.5465. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 33 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.564\n",
      "\t Val. Loss: 0.547\n",
      "\n",
      "Valid loss improved from 0.5465 to 0.5436. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 34 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.560\n",
      "\t Val. Loss: 0.544\n",
      "\n",
      "Valid loss improved from 0.5436 to 0.5391. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 35 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.559\n",
      "\t Val. Loss: 0.539\n",
      "\n",
      "Valid loss improved from 0.5391 to 0.5316. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 36 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.550\n",
      "\t Val. Loss: 0.532\n",
      "\n",
      "Epoch: 37 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.542\n",
      "\t Val. Loss: 0.551\n",
      "\n",
      "Epoch: 38 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.540\n",
      "\t Val. Loss: 0.642\n",
      "\n",
      "Epoch: 39 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.538\n",
      "\t Val. Loss: 0.542\n",
      "\n",
      "Valid loss improved from 0.5316 to 0.5250. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 40 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.533\n",
      "\t Val. Loss: 0.525\n",
      "\n",
      "Epoch: 41 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.524\n",
      "\t Val. Loss: 0.555\n",
      "\n",
      "Valid loss improved from 0.5250 to 0.5246. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 42 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.523\n",
      "\t Val. Loss: 0.525\n",
      "\n",
      "Valid loss improved from 0.5246 to 0.5242. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 43 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.518\n",
      "\t Val. Loss: 0.524\n",
      "\n",
      "Epoch: 44 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.513\n",
      "\t Val. Loss: 0.534\n",
      "\n",
      "Valid loss improved from 0.5242 to 0.5030. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 45 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.506\n",
      "\t Val. Loss: 0.503\n",
      "\n",
      "Epoch: 46 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.508\n",
      "\t Val. Loss: 0.504\n",
      "\n",
      "Valid loss improved from 0.5030 to 0.4910. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 47 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.501\n",
      "\t Val. Loss: 0.491\n",
      "\n",
      "Valid loss improved from 0.4910 to 0.4846. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 48 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.500\n",
      "\t Val. Loss: 0.485\n",
      "\n",
      "Epoch: 49 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.498\n",
      "\t Val. Loss: 0.488\n",
      "\n",
      "Valid loss improved from 0.4846 to 0.4764. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 50 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.492\n",
      "\t Val. Loss: 0.476\n",
      "\n",
      "Epoch: 51 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.491\n",
      "\t Val. Loss: 0.484\n",
      "\n",
      "Valid loss improved from 0.4764 to 0.4680. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 52 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.488\n",
      "\t Val. Loss: 0.468\n",
      "\n",
      "Epoch: 53 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.482\n",
      "\t Val. Loss: 0.473\n",
      "\n",
      "Epoch: 54 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.487\n",
      "\t Val. Loss: 0.479\n",
      "\n",
      "Epoch: 55 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.487\n",
      "\t Val. Loss: 0.486\n",
      "\n",
      "Valid loss improved from 0.4680 to 0.4676. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 56 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.486\n",
      "\t Val. Loss: 0.468\n",
      "\n",
      "Epoch: 57 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.479\n",
      "\t Val. Loss: 0.470\n",
      "\n",
      "Epoch: 58 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.476\n",
      "\t Val. Loss: 0.476\n",
      "\n",
      "Valid loss improved from 0.4676 to 0.4565. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 59 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.472\n",
      "\t Val. Loss: 0.457\n",
      "\n",
      "Valid loss improved from 0.4565 to 0.4532. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 60 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.468\n",
      "\t Val. Loss: 0.453\n",
      "\n",
      "Valid loss improved from 0.4532 to 0.4513. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 61 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.463\n",
      "\t Val. Loss: 0.451\n",
      "\n",
      "Valid loss improved from 0.4513 to 0.4498. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 62 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.459\n",
      "\t Val. Loss: 0.450\n",
      "\n",
      "Valid loss improved from 0.4498 to 0.4491. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 63 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.457\n",
      "\t Val. Loss: 0.449\n",
      "\n",
      "Epoch: 64 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.458\n",
      "\t Val. Loss: 0.460\n",
      "\n",
      "Epoch: 65 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.457\n",
      "\t Val. Loss: 0.474\n",
      "\n",
      "Epoch: 66 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.454\n",
      "\t Val. Loss: 0.509\n",
      "\n",
      "Epoch: 67 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.452\n",
      "\t Val. Loss: 0.458\n",
      "\n",
      "Epoch: 68 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.446\n",
      "\t Val. Loss: 0.458\n",
      "\n",
      "Valid loss improved from 0.4491 to 0.4415. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 69 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.447\n",
      "\t Val. Loss: 0.441\n",
      "\n",
      "Epoch: 70 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.444\n",
      "\t Val. Loss: 0.445\n",
      "\n",
      "Epoch: 71 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.441\n",
      "\t Val. Loss: 0.456\n",
      "\n",
      "Epoch: 72 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.436\n",
      "\t Val. Loss: 0.467\n",
      "\n",
      "Epoch: 73 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.434\n",
      "\t Val. Loss: 0.485\n",
      "\n",
      "Epoch: 74 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.434\n",
      "\t Val. Loss: 0.459\n",
      "\n",
      "Epoch: 75 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.443\n",
      "\t Val. Loss: 0.459\n",
      "\n",
      "Valid loss improved from 0.4415 to 0.4266. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 76 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.434\n",
      "\t Val. Loss: 0.427\n",
      "\n",
      "Valid loss improved from 0.4266 to 0.4239. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 77 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.437\n",
      "\t Val. Loss: 0.424\n",
      "\n",
      "Valid loss improved from 0.4239 to 0.4137. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 78 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.427\n",
      "\t Val. Loss: 0.414\n",
      "\n",
      "Valid loss improved from 0.4137 to 0.4129. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 79 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.428\n",
      "\t Val. Loss: 0.413\n",
      "\n",
      "Epoch: 80 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.427\n",
      "\t Val. Loss: 0.415\n",
      "\n",
      "Valid loss improved from 0.4129 to 0.4075. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 81 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.427\n",
      "\t Val. Loss: 0.408\n",
      "\n",
      "Epoch: 82 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.424\n",
      "\t Val. Loss: 0.408\n",
      "\n",
      "Valid loss improved from 0.4075 to 0.4054. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 83 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.422\n",
      "\t Val. Loss: 0.405\n",
      "\n",
      "Valid loss improved from 0.4054 to 0.4052. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 84 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.417\n",
      "\t Val. Loss: 0.405\n",
      "\n",
      "Epoch: 85 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.421\n",
      "\t Val. Loss: 0.415\n",
      "\n",
      "Epoch: 86 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.433\n",
      "\t Val. Loss: 0.406\n",
      "\n",
      "Epoch: 87 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.420\n",
      "\t Val. Loss: 0.407\n",
      "\n",
      "Valid loss improved from 0.4052 to 0.3997. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 88 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.419\n",
      "\t Val. Loss: 0.400\n",
      "\n",
      "Epoch: 89 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.418\n",
      "\t Val. Loss: 0.400\n",
      "\n",
      "Valid loss improved from 0.3997 to 0.3989. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 90 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.413\n",
      "\t Val. Loss: 0.399\n",
      "\n",
      "Valid loss improved from 0.3989 to 0.3957. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 91 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.414\n",
      "\t Val. Loss: 0.396\n",
      "\n",
      "Epoch: 92 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.411\n",
      "\t Val. Loss: 0.398\n",
      "\n",
      "Epoch: 93 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.412\n",
      "\t Val. Loss: 0.411\n",
      "\n",
      "Epoch: 94 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.412\n",
      "\t Val. Loss: 0.397\n",
      "\n",
      "Valid loss improved from 0.3957 to 0.3944. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 95 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.411\n",
      "\t Val. Loss: 0.394\n",
      "\n",
      "Epoch: 96 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.408\n",
      "\t Val. Loss: 0.396\n",
      "\n",
      "Valid loss improved from 0.3944 to 0.3933. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 97 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.407\n",
      "\t Val. Loss: 0.393\n",
      "\n",
      "Valid loss improved from 0.3933 to 0.3908. Saving checkpoint: working/files/drive_checkpoint_ori.pth\n",
      "Epoch: 98 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.411\n",
      "\t Val. Loss: 0.391\n",
      "\n",
      "Epoch: 99 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.408\n",
      "\t Val. Loss: 0.400\n",
      "\n",
      "Epoch: 100 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.406\n",
      "\t Val. Loss: 0.397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# from data import DriveDataset\n",
    "# from model import build_unet\n",
    "# from loss import DiceLoss, DiceBCELoss\n",
    "# from utils import seeding, create_dir, epoch_time\n",
    "\n",
    "'''训练深度学习模型'''\n",
    "def train(model, loader, optimizer, loss_fn, device, show_images=False):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        # if i == 1 and show_images:\n",
    "        #    # 显示第一批图像和掩码\n",
    "        #     img = x[0].cpu().numpy()  # 假设图像是CHW格式\n",
    "        #     img = np.transpose(img, (1, 2, 0))  # 转换为HWC格式\n",
    "        #     img = img[..., ::-1]  # 将BGR转换为RGB\n",
    "        #     mask = y[0].cpu().numpy()  # 假设掩码是CHW格式\n",
    "        #     mask = np.transpose(mask, (1, 2, 0))  # 转换为HWC格式\n",
    "\n",
    "        #     plt.figure(figsize=(12, 6))\n",
    "\n",
    "        #     plt.subplot(1, 2, 1)\n",
    "        #     plt.imshow(img)\n",
    "        #     plt.title(\"Sample Image\")\n",
    "\n",
    "        #     plt.subplot(1, 2, 2)\n",
    "        #     plt.imshow(mask, cmap='gray')\n",
    "        #     plt.title(\"Corresponding Mask\")\n",
    "\n",
    "        #     plt.show()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    #计算整个epoch的平均损失\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Directories \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    train_x = sorted(glob(\"working/new_data/train/image/*\"))\n",
    "    train_y = sorted(glob(\"working/new_data/train/mask/*\"))\n",
    "\n",
    "    valid_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    valid_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "\n",
    "    data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\n",
    "    print(data_str)\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (H, W)\n",
    "    batch_size = 64\n",
    "    num_epochs = 100   \n",
    "    lr = 1e-3\n",
    "    checkpoint_path = \"working/files/drive_checkpoint_ori.pth\"\n",
    "\n",
    "    \"\"\" Dataset and loader \"\"\"\n",
    "    train_dataset = DriveDataset(train_x, train_y)\n",
    "    valid_dataset = DriveDataset(valid_x, valid_y)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   ## GTX 1060 6GB\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "    \"\"\" Training the model \"\"\"\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        #该轮训练的平均损失值 train_loss\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device, show_images=True)\n",
    "        #返回验证损失 valid_loss\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        \"\"\" Saving the model \"\"\"\n",
    "        if valid_loss < best_valid_loss:\n",
    "            data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
    "        data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
    "        data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
    "        print(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:56:04.789919Z",
     "iopub.status.busy": "2025-12-26T10:56:04.789291Z",
     "iopub.status.idle": "2025-12-26T10:56:09.112965Z",
     "shell.execute_reply": "2025-12-26T10:56:09.112196Z",
     "shell.execute_reply.started": "2025-12-26T10:56:04.789886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715224/705512160.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
      "  0%|          | 0/20 [00:00<?, ?it/s][ WARN:0@335.082] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
      " 15%|█▌        | 3/20 [00:00<00:01, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6431, f1:0.7828,recall:0.8328,precision:0.738,acc:0.9589,specificity:0.971\n",
      ":-- jaccard:0.6923, f1:0.8181,recall:0.8203,precision:0.816,acc:0.9628,specificity:0.979\n",
      ":-- jaccard:0.6092, f1:0.7571,recall:0.6885,precision:0.841,acc:0.9560,specificity:0.986\n",
      ":-- jaccard:0.6627, f1:0.7972,recall:0.7612,precision:0.837,acc:0.9645,specificity:0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:00<00:00, 17.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6521, f1:0.7894,recall:0.7375,precision:0.849,acc:0.9633,specificity:0.987\n",
      ":-- jaccard:0.6204, f1:0.7657,recall:0.6940,precision:0.854,acc:0.9588,specificity:0.987\n",
      ":-- jaccard:0.6229, f1:0.7677,recall:0.7340,precision:0.805,acc:0.9593,specificity:0.982\n",
      ":-- jaccard:0.6008, f1:0.7506,recall:0.6798,precision:0.838,acc:0.9615,specificity:0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:00<00:00, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6172, f1:0.7633,recall:0.7158,precision:0.818,acc:0.9640,specificity:0.986\n",
      ":-- jaccard:0.6268, f1:0.7706,recall:0.7578,precision:0.784,acc:0.9633,specificity:0.981\n",
      ":-- jaccard:0.6124, f1:0.7596,recall:0.7662,precision:0.753,acc:0.9571,specificity:0.976\n",
      ":-- jaccard:0.6318, f1:0.7743,recall:0.7380,precision:0.814,acc:0.9631,specificity:0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:00<00:00, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6351, f1:0.7768,recall:0.7357,precision:0.823,acc:0.9587,specificity:0.983\n",
      ":-- jaccard:0.6360, f1:0.7775,recall:0.7691,precision:0.786,acc:0.9644,specificity:0.982\n",
      ":-- jaccard:0.6389, f1:0.7796,recall:0.7623,precision:0.798,acc:0.9693,specificity:0.985\n",
      ":-- jaccard:0.6254, f1:0.7695,recall:0.7572,precision:0.782,acc:0.9591,specificity:0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6083, f1:0.7564,recall:0.7126,precision:0.806,acc:0.9613,specificity:0.984\n",
      ":-- jaccard:0.6323, f1:0.7747,recall:0.8042,precision:0.747,acc:0.9629,specificity:0.977\n",
      ":-- jaccard:0.6892, f1:0.8160,recall:0.8202,precision:0.812,acc:0.9693,specificity:0.983\n",
      ":-- jaccard:0.6343, f1:0.7762,recall:0.8132,precision:0.742,acc:0.9655,specificity:0.978\n",
      "\n",
      "Overall---Jaccard: 0.6346 - F1: 0.7762 - Sensitivity: 0.7550 - Precision: 0.8022 - Acc: 0.9621 - Specificity:0.9821\n",
      "FPS:  328.76002806093453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import os, time\n",
    "from operator import add\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# from model import build_unet\n",
    "# from utils import create_dir, seeding\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    # 使用混淆矩阵计算 TP, FP, FN, TN\n",
    "    # labels=[0, 1] 确保即使数据中缺少某一类也能返回 2x2 矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    # Dice Coefficient (F1 Score) = 2 * TP / (2 * TP + FP + FN)\n",
    "    score_f1 = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "\n",
    "    # Jaccard (IoU) = TP / (TP + FP + FN)\n",
    "    score_jaccard = tp / (tp + fp + fn + 1e-6)\n",
    "\n",
    "    # Sensitivity (Recall) = TP / (TP + FN)\n",
    "    score_recall = tp / (tp + fn + 1e-6)\n",
    "\n",
    "    # Specificity = TN / (TN + FP)\n",
    "    score_specificity = tn / (tn + fp + 1e-6)\n",
    "\n",
    "    # Precision = TP / (TP + FP)\n",
    "    score_precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    # Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    score_acc = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, score_specificity]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(\"working/results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    test_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (W, H)\n",
    "    checkpoint_path = \"working/files/drive_checkpoint_ori.pth\"\n",
    "\n",
    "    \"\"\" Load the checkpoint \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "    \n",
    "    # Lists to store metrics for each image for plotting\n",
    "    image_indices = []\n",
    "    jaccard_scores = []\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    specificity_scores = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "        ## image = cv2.resize(image, size)\n",
    "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
    "        x = x/255.0\n",
    "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "        ## mask = cv2.resize(mask, size)\n",
    "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
    "        y = y/255.0\n",
    "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            pred_y = model(x)\n",
    "            pred_y = torch.sigmoid(pred_y)\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            print(f\":-- jaccard:{score[0]:1.4f}, f1:{score[1]:1.4f},recall:{score[2]:1.4f},precision:{score[3]:1.3f},acc:{score[4]:1.4f},specificity:{score[5]:1.3f}\")\n",
    "            \n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            \n",
    "            # Store for plotting\n",
    "            image_indices.append(i)\n",
    "            jaccard_scores.append(score[0])\n",
    "            f1_scores.append(score[1])\n",
    "            recall_scores.append(score[2])\n",
    "            specificity_scores.append(score[5])\n",
    "            \n",
    "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
    "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        pred_y = mask_parse(pred_y)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(f\"working/results/{name}.png\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    spec = metrics_score[5]/len(test_x)\n",
    "    print(f\"\\nOverall---Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Sensitivity: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - Specificity:{spec:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 946814,
     "sourceId": 1604025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pampc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
