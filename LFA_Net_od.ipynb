{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:27.187106Z",
     "iopub.status.busy": "2025-12-26T10:17:27.186304Z",
     "iopub.status.idle": "2025-12-26T10:17:38.866947Z",
     "shell.execute_reply": "2025-12-26T10:17:38.866281Z",
     "shell.execute_reply.started": "2025-12-26T10:17:27.187068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"config.py\"):\n",
    "    print(\"Warning: Found 'config.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "if os.path.exists(\"torch.py\"):\n",
    "    print(\"Warning: Found 'torch.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "\n",
    "# 优先导入 torch\n",
    "import torch\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast, RandomCrop, RandomRotate90, RandomGridShuffle\n",
    "\n",
    "\"\"\" Create a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "'''加载数据：原图+标签'''\n",
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "'''\n",
    "增强数据\n",
    "对图像及其对应mask数据增强\n",
    "'''\n",
    "def load_data_with_od(path):\n",
    "    # 加载原图、血管Mask、视盘Mask\n",
    "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "    train_od = sorted(glob(os.path.join(path, \"training\", \"od_masks\", \"*.png\"))) # 新增\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "    test_od = sorted(glob(os.path.join(path, \"test\", \"od_masks\", \"*.png\"))) # 新增\n",
    "\n",
    "    return (train_x, train_y, train_od), (test_x, test_y, test_od)\n",
    "\n",
    "def augment_data_triple_triple(images, masks, od_masks, save_path, augment=True):\n",
    "    size = (560, 560)\n",
    "    \n",
    "    # 确保保存路径存在\n",
    "    create_dir(os.path.join(save_path, \"image\"))\n",
    "    create_dir(os.path.join(save_path, \"mask\"))\n",
    "    create_dir(os.path.join(save_path, \"od_mask\")) # 新增\n",
    "\n",
    "    for idx, (x, y, od) in tqdm(enumerate(zip(images, masks, od_masks)), total=len(images)):\n",
    "        name = x.split(os.sep)[-1].split(\".\")[0]\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "        od = cv2.imread(od, cv2.IMREAD_GRAYSCALE) # 读取视盘Mask\n",
    "\n",
    "        if augment:\n",
    "            transformations = [\n",
    "                HorizontalFlip(p=1.0),\n",
    "                VerticalFlip(p=1.0),\n",
    "                Rotate(limit=45, p=1.0),\n",
    "                RandomBrightnessContrast(p=0.6),\n",
    "                RandomCrop(300, 300, p=0.8),\n",
    "                RandomRotate90(p=1.0),\n",
    "                RandomGridShuffle(p=0.7)\n",
    "            ]\n",
    "            \n",
    "            # 使用列表保存增强结果\n",
    "            X, Y, OD = [x], [y], [od]\n",
    "\n",
    "            for aug in transformations:\n",
    "                # Albumentations 支持多 Mask: use masks=[mask1, mask2]\n",
    "                augmented = aug(image=x, masks=[y, od]) \n",
    "                X.append(augmented[\"image\"])\n",
    "                Y.append(augmented[\"masks\"][0])\n",
    "                OD.append(augmented[\"masks\"][1])\n",
    "        else:\n",
    "            X, Y, OD = [x], [y], [od]\n",
    "\n",
    "        index = 0\n",
    "        for i, m, o in zip(X, Y, OD):\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "            o = cv2.resize(o, size)\n",
    "\n",
    "            tmp_name = f\"{name}_{index}.png\"\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_path, \"image\", tmp_name), i)\n",
    "            cv2.imwrite(os.path.join(save_path, \"mask\", tmp_name), m)\n",
    "            cv2.imwrite(os.path.join(save_path, \"od_mask\", tmp_name), o) # 保存视盘Mask\n",
    "            index += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Load the data \"\"\"\n",
    "    # 修改为相对路径\n",
    "    data_path = \"data/DRIVE/\"\n",
    "    \n",
    "    if os.path.exists(data_path):\n",
    "        (train_x, train_y, train_od), (test_x, test_y, test_od) = load_data_with_od(data_path)\n",
    "\n",
    "        print(f\"Train: {len(train_x)} - {len(train_y)} - {len(train_od)}\")\n",
    "        print(f\"Test: {len(test_x)} - {len(test_y)} - {len(test_od)}\")\n",
    "\n",
    "        \"\"\" Create directories to save the augmented data \"\"\"\n",
    "        create_dir(\"working/new_data/train/image/\")\n",
    "        create_dir(\"working/new_data/train/mask/\")\n",
    "        create_dir(\"working/new_data/test/image/\")\n",
    "        create_dir(\"working/new_data/test/mask/\")\n",
    "\n",
    "        \"\"\" Data augmentation \"\"\"\n",
    "        # 取消注释以运行数据增强\n",
    "        augment_data_triple_triple(train_x, train_y, train_od, \"working/new_data/train/\", augment=True)\n",
    "        augment_data_triple_triple(test_x, test_y, test_od, \"working/new_data/test/\", augment=False)\n",
    "    else:\n",
    "        print(f\"Data path not found: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:38.868551Z",
     "iopub.status.busy": "2025-12-26T10:17:38.868200Z",
     "iopub.status.idle": "2025-12-26T10:17:40.435461Z",
     "shell.execute_reply": "2025-12-26T10:17:40.434747Z",
     "shell.execute_reply.started": "2025-12-26T10:17:38.868526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model (LFA-Net)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalModulation(nn.Module):\n",
    "    def __init__(self, in_channels, gamma=2.0, alpha=0.25):\n",
    "        super(FocalModulation, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.gap(x)\n",
    "        max_val = self.gmp(x)\n",
    "        modulation = (max_val - mean) * self.alpha\n",
    "        modulation = self.conv(modulation)\n",
    "        modulation = self.sigmoid(modulation)\n",
    "        scaled_inputs = x * modulation\n",
    "        outputs = torch.pow(scaled_inputs, self.gamma)\n",
    "        return outputs\n",
    "\n",
    "class FocalModulationContextAggregation(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(FocalModulationContextAggregation, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, filters, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_ctx = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.focal_mod = FocalModulation(filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.relu1(self.conv1(x))\n",
    "        c2 = self.relu2(self.conv2(x))\n",
    "        \n",
    "        global_context = self.gap(c2)\n",
    "        global_context = self.sigmoid(self.conv_ctx(global_context))\n",
    "        global_context = c1 * global_context\n",
    "        \n",
    "        fm = self.focal_mod(global_context)\n",
    "        return torch.cat([c1, fm], dim=1)\n",
    "\n",
    "class VisionMambaInspired(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.1):\n",
    "        super(VisionMambaInspired, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.token_mixer = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.channel_mixer = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        shortcut = x\n",
    "        x_perm = x.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm1(x_perm).permute(0, 3, 1, 2)\n",
    "        x_tm = self.token_mixer(x_norm) + shortcut\n",
    "        \n",
    "        shortcut = x_tm\n",
    "        x_perm = x_tm.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm2(x_perm)\n",
    "        x_cm = self.channel_mixer(x_norm)\n",
    "        x_cm = x_cm.permute(0, 3, 1, 2)\n",
    "        \n",
    "        return x_cm + shortcut\n",
    "\n",
    "class LiteFusionAttention(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(LiteFusionAttention, self).__init__()\n",
    "        self.proj1 = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(filters)\n",
    "        self.conv = nn.Conv2d(filters, filters, kernel_size=3, padding=1)\n",
    "        self.fmca = FocalModulationContextAggregation(filters, filters)\n",
    "        self.proj2 = nn.Conv2d(2 * filters, filters, kernel_size=1)\n",
    "        self.vm = VisionMambaInspired(filters)\n",
    "        \n",
    "        self.res_proj = nn.Conv2d(in_channels, filters, kernel_size=1) if in_channels != filters else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = self.proj1(x)\n",
    "        \n",
    "        x_perm = input_tensor.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm(x_perm).permute(0, 3, 1, 2)\n",
    "        \n",
    "        x_conv = self.conv(x_norm)\n",
    "        x_fmca = self.fmca(x_conv)\n",
    "        x_proj = self.proj2(x_fmca)\n",
    "        \n",
    "        res = self.res_proj(x) if isinstance(self.res_proj, nn.Conv2d) else input_tensor\n",
    "        out = x_proj + res\n",
    "        \n",
    "        out = self.vm(out)\n",
    "        return out\n",
    "\n",
    "class RA_AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, k):\n",
    "        super(RA_AttentionBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.conv = nn.Conv2d(in_channels, k * n_classes, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(k * n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        f = self.relu(self.bn(self.conv(x)))\n",
    "        \n",
    "        x1 = self.gmp(f)\n",
    "        x2 = self.gap(f)\n",
    "        x_mul = x1 * x2\n",
    "        \n",
    "        x_reshape = x_mul.view(b, self.n_classes, self.k)\n",
    "        s = torch.mean(x_reshape, dim=-1, keepdim=False)\n",
    "        \n",
    "        f_perm = f.permute(0, 2, 3, 1)\n",
    "        f_reshape = f_perm.view(b, h, w, self.n_classes, self.k)\n",
    "        f_mean = torch.mean(f_reshape, dim=-1, keepdim=False)\n",
    "        \n",
    "        s_expanded = s.view(b, 1, 1, self.n_classes)\n",
    "        x_weighted = f_mean * s_expanded\n",
    "        \n",
    "        m = torch.mean(x_weighted, dim=-1, keepdim=True)\n",
    "        m = m.permute(0, 3, 1, 2)\n",
    "        \n",
    "        semantic = x * m\n",
    "        return semantic\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.5):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv3x3_dilated = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2, bias=False)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1x1(x)\n",
    "        c3 = self.conv3x3(x)\n",
    "        c3d = self.conv3x3_dilated(x)\n",
    "        out = c1 + c3 + c3d\n",
    "        out = self.leaky_relu(out)\n",
    "        return out\n",
    "\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self, input_channels=4, num_classes=1, feature_scale=2, dropout=0.5):\n",
    "        super(build_unet, self).__init__()\n",
    "        filters = [int(x / feature_scale) for x in [16, 32, 64]]\n",
    "        \n",
    "        self.conv1 = ConvBlock(input_channels, filters[0], dropout)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.bn1 = nn.BatchNorm2d(filters[0])\n",
    "        \n",
    "        self.conv2 = ConvBlock(filters[0], filters[1], dropout)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.bn2 = nn.BatchNorm2d(filters[1])\n",
    "        \n",
    "        self.conv3 = ConvBlock(filters[1], filters[2], dropout)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bn3 = nn.BatchNorm2d(filters[2])\n",
    "        \n",
    "        self.lfa = LiteFusionAttention(filters[2], filters=32)\n",
    "        \n",
    "        lfa_out_channels = 32 \n",
    "        self.att1 = RA_AttentionBlock(lfa_out_channels, 1, 16)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(lfa_out_channels * 2, filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att2 = RA_AttentionBlock(filters[1], 1, 16)\n",
    "        self.dec_conv1 = nn.Conv2d(filters[1] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att3 = RA_AttentionBlock(filters[0], 1, 16)\n",
    "        self.dec_conv2 = nn.Conv2d(filters[0] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(filters[2], filters[0], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_conv3 = nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.final = nn.Conv2d(filters[0], num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.bn1(self.pool1(c1))\n",
    "        \n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.bn2(self.pool2(c2))\n",
    "        \n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.bn3(self.pool3(c3))\n",
    "        \n",
    "        lfa = self.lfa(p3)\n",
    "        \n",
    "        att1 = self.att1(lfa)\n",
    "        fused = torch.cat([att1, lfa], dim=1)\n",
    "        \n",
    "        d1 = self.up1(fused)\n",
    "        if d1.size() != c2.size():\n",
    "             d1 = F.interpolate(d1, size=c2.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        att2 = self.att2(c2)\n",
    "        d1 = torch.cat([att2, d1], dim=1)\n",
    "        d1 = self.relu1(self.dec_conv1(d1))\n",
    "        \n",
    "        d2 = self.up2(d1)\n",
    "        if d2.size() != c1.size():\n",
    "             d2 = F.interpolate(d2, size=c1.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        att3 = self.att3(c1)\n",
    "        d2 = torch.cat([att3, d2], dim=1)\n",
    "        d2 = self.relu2(self.dec_conv2(d2))\n",
    "        \n",
    "        d3 = self.up3(d2)\n",
    "        if d3.size() != x.size():\n",
    "             d3 = F.interpolate(d3, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        d3 = self.relu3(self.dec_conv3(d3))\n",
    "        \n",
    "        out = self.final(d3)\n",
    "        return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((2, 4, 560, 560))\n",
    "    f = build_unet()\n",
    "    y = f(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.437315Z",
     "iopub.status.busy": "2025-12-26T10:17:40.437071Z",
     "iopub.status.idle": "2025-12-26T10:17:40.443522Z",
     "shell.execute_reply": "2025-12-26T10:17:40.442839Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.437294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, od_masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.od_masks_path = od_masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image / 255.0 \n",
    "        # (H, W, 3)\n",
    "        \n",
    "        \"\"\" Reading OD mask \"\"\"\n",
    "        od_mask = cv2.imread(self.od_masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        od_mask = od_mask / 255.0\n",
    "        od_mask = np.expand_dims(od_mask, axis=-1) # (H, W, 1)\n",
    "        \n",
    "        \"\"\" Concatenate: 融合 Image 和 OD Mask \"\"\"\n",
    "        # 结果形状: (H, W, 4) ->  transpose -> (4, H, W)\n",
    "        input_tensor = np.concatenate([image, od_mask], axis=-1)\n",
    "        \n",
    "        input_tensor = np.transpose(input_tensor, (2, 0, 1))\n",
    "        input_tensor = input_tensor.astype(np.float32)\n",
    "        input_tensor = torch.from_numpy(input_tensor)\n",
    "\n",
    "        \"\"\" Reading label mask \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return input_tensor, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.445318Z",
     "iopub.status.busy": "2025-12-26T10:17:40.445100Z",
     "iopub.status.idle": "2025-12-26T10:17:40.467440Z",
     "shell.execute_reply": "2025-12-26T10:17:40.466743Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.445297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.468545Z",
     "iopub.status.busy": "2025-12-26T10:17:40.468339Z",
     "iopub.status.idle": "2025-12-26T10:17:40.482989Z",
     "shell.execute_reply": "2025-12-26T10:17:40.482370Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.468525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\"\"\" Seeding the randomness. \"\"\"\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\" Create a directory. \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Calculate the time taken \"\"\"\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.483887Z",
     "iopub.status.busy": "2025-12-26T10:17:40.483664Z",
     "iopub.status.idle": "2025-12-26T10:56:04.787586Z",
     "shell.execute_reply": "2025-12-26T10:56:04.786752Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.483865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# from data import DriveDataset\n",
    "# from model import build_unet\n",
    "# from loss import DiceLoss, DiceBCELoss\n",
    "# from utils import seeding, create_dir, epoch_time\n",
    "\n",
    "'''训练深度学习模型'''\n",
    "def train(model, loader, optimizer, loss_fn, device, show_images=False):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        # if i == 1 and show_images:\n",
    "        #    # 显示第一批图像和掩码\n",
    "        #     img = x[0].cpu().numpy()  # 假设图像是CHW格式\n",
    "        #     img = np.transpose(img, (1, 2, 0))  # 转换为HWC格式\n",
    "        #     img = img[..., ::-1]  # 将BGR转换为RGB\n",
    "        #     mask = y[0].cpu().numpy()  # 假设掩码是CHW格式\n",
    "        #     mask = np.transpose(mask, (1, 2, 0))  # 转换为HWC格式\n",
    "\n",
    "        #     plt.figure(figsize=(12, 6))\n",
    "\n",
    "        #     plt.subplot(1, 2, 1)\n",
    "        #     plt.imshow(img)\n",
    "        #     plt.title(\"Sample Image\")\n",
    "\n",
    "        #     plt.subplot(1, 2, 2)\n",
    "        #     plt.imshow(mask, cmap='gray')\n",
    "        #     plt.title(\"Corresponding Mask\")\n",
    "\n",
    "        #     plt.show()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    #计算整个epoch的平均损失\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Directories \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    train_x = sorted(glob(\"working/new_data/train/image/*\"))\n",
    "    train_y = sorted(glob(\"working/new_data/train/mask/*\"))\n",
    "    train_od = sorted(glob(\"working/new_data/train/od_mask/*\")) # 加载增强后的 OD Mask\n",
    "\n",
    "    valid_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    valid_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "    valid_od = sorted(glob(\"working/new_data/test/od_mask/*\"))\n",
    "\n",
    "    data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\n",
    "    print(data_str)\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (H, W)\n",
    "    batch_size = 64\n",
    "    num_epochs = 100   \n",
    "    lr = 1e-3\n",
    "    checkpoint_path = \"working/files/drive_checkpoint.pth\"\n",
    "\n",
    "    \"\"\" Dataset and loader \"\"\"\n",
    "    train_dataset = DriveDataset(train_x, train_y, train_od)\n",
    "    valid_dataset = DriveDataset(valid_x, valid_y, valid_od)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   ## GTX 1060 6GB\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "    \"\"\" Training the model \"\"\"\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        #该轮训练的平均损失值 train_loss\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device, show_images=True)\n",
    "        #返回验证损失 valid_loss\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        \"\"\" Saving the model \"\"\"\n",
    "        if valid_loss < best_valid_loss:\n",
    "            data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
    "        data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
    "        data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
    "        print(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:56:04.789919Z",
     "iopub.status.busy": "2025-12-26T10:56:04.789291Z",
     "iopub.status.idle": "2025-12-26T10:56:09.112965Z",
     "shell.execute_reply": "2025-12-26T10:56:09.112196Z",
     "shell.execute_reply.started": "2025-12-26T10:56:04.789886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "import os, time\n",
    "from operator import add\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 假设 build_unet, create_dir, seeding 等函数已经在上下文中定义\n",
    "# 如果是在 notebook 中，确保上面的 cell 已经运行\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" 计算指标 (保持不变) \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    score_f1 = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "    score_jaccard = tp / (tp + fp + fn + 1e-6)\n",
    "    score_recall = tp / (tp + fn + 1e-6)\n",
    "    score_specificity = tn / (tn + fp + 1e-6)\n",
    "    score_precision = tp / (tp + fp + 1e-6)\n",
    "    score_acc = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, score_specificity]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "    return mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(\"working/results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    # 1. 加载三个路径列表：图像、金标准Mask、视盘Mask\n",
    "    test_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "    test_od = sorted(glob(\"working/new_data/test/od_mask/*\")) # 【新增】加载视盘Mask路径\n",
    "\n",
    "    # 检查文件数量是否匹配\n",
    "    if len(test_x) != len(test_od):\n",
    "        print(f\"警告: 图像数量 ({len(test_x)}) 与视盘Mask数量 ({len(test_od)}) 不匹配！\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (W, H)\n",
    "    checkpoint_path = \"working/files/drive_checkpoint_od.pth\"\n",
    "\n",
    "    \"\"\" Load the checkpoint \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 初始化模型时，确保 input_channels=4\n",
    "    model = build_unet(input_channels=4) \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 如果训练时用了 DataParallel，这里加载权重可能需要处理 'module.' 前缀\n",
    "    # 这里假设直接加载\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "    \n",
    "    # 遍历 Image, Label, OD_Mask\n",
    "    for i, (x_path, y_path, od_path) in tqdm(enumerate(zip(test_x, test_y, test_od)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" 1. 处理原图 (RGB) \"\"\"\n",
    "        image = cv2.imread(x_path, cv2.IMREAD_COLOR) \n",
    "        # image 已经是 560x560 (数据增强阶段处理过)\n",
    "        x = np.transpose(image, (2, 0, 1))      ## (3, 560, 560)\n",
    "        x = x / 255.0\n",
    "        \n",
    "        \"\"\" 2. 处理视盘 Mask (OD) \"\"\"\n",
    "        od_mask = cv2.imread(od_path, cv2.IMREAD_GRAYSCALE) # 读取单通道\n",
    "        # od_mask 已经是 560x560\n",
    "        od_mask = od_mask / 255.0\n",
    "        od_mask = np.expand_dims(od_mask, axis=0) ## (1, 560, 560)\n",
    "\n",
    "        \"\"\" 3. 合并通道 (Concatenate) \"\"\"\n",
    "        # 将 RGB (3, H, W) 和 OD (1, H, W) 在通道维度合并 -> (4, H, W)\n",
    "        x_concat = np.concatenate([x, od_mask], axis=0)\n",
    "        \n",
    "        # 转为 Tensor 并增加 Batch 维度 -> (1, 4, 560, 560)\n",
    "        x_tensor = np.expand_dims(x_concat, axis=0) \n",
    "        x_tensor = x_tensor.astype(np.float32)\n",
    "        x_tensor = torch.from_numpy(x_tensor).to(device)\n",
    "\n",
    "        \"\"\" Reading label mask \"\"\"\n",
    "        mask = cv2.imread(y_path, cv2.IMREAD_GRAYSCALE)\n",
    "        y = np.expand_dims(mask, axis=0)            \n",
    "        y = y / 255.0\n",
    "        y = np.expand_dims(y, axis=0)               \n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction \"\"\"\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # 模型输入现在是 4 通道，不会报错了\n",
    "            pred_y = model(x_tensor) \n",
    "            pred_y = torch.sigmoid(pred_y)\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            # print(f\":-- jaccard:{score[0]:1.4f} ...\") \n",
    "            \n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            \n",
    "            # 后处理用于保存图片\n",
    "            pred_y = pred_y[0].cpu().numpy()        \n",
    "            pred_y = np.squeeze(pred_y, axis=0)     \n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        pred_y_viz = mask_parse(pred_y)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        # 拼接图片用于展示结果\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, pred_y_viz * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(f\"working/results/{name}.png\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    spec = metrics_score[5]/len(test_x)\n",
    "    print(f\"\\nOverall---Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Sensitivity: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - Specificity:{spec:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 946814,
     "sourceId": 1604025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pampc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
