{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5293,
     "status": "ok",
     "timestamp": 1725042119290,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "pghZrtcZNNWn",
    "outputId": "902a3fd2-a3a8-4213-c40a-9f3f591c763b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mis_gpu_available(\n\u001b[1;32m      3\u001b[0m     cuda_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_cuda_compute_capability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3922,
     "status": "ok",
     "timestamp": 1725042123206,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "02j5H1VjF4VM",
    "outputId": "9ef7cb8e-0507-4ba4-b16e-6599ecc7722a"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# filename = \"/homes/imransharif/Mehwish/Dataset/DRIVE_Final_880.zip\"\n",
    "\n",
    "# with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#     zip_ref.extractall()\n",
    "#     print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24156,
     "status": "ok",
     "timestamp": 1725042147347,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "x0Mh8O8Idis-",
    "outputId": "e0d6864c-d6b6-42a9-a2e7-4ae7f7251116"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "!pip install keras-preprocessing\n",
    "!pip install scikit-image\n",
    "import tensorflow as tf\n",
    "import time\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "#from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "# from skimage.io import imread, imshow, concatenate_images\n",
    "# from skimage.transform import resize\n",
    "# from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import imageio\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Resizing\n",
    "from keras.layers import Lambda, RepeatVector, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.layers import MaxPooling2D, GlobalMaxPool2D, AveragePooling2D\n",
    "from keras.regularizers import l2\n",
    "#from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "#from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.losses import *\n",
    "from keras import backend as keras\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras_preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "# import skimage.io as io\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "# import skimage\n",
    "from keras.initializers import Constant\n",
    "\n",
    "# from skimage.morphology import disk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from skimage.measure import label, regionprops\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import layers, models\n",
    "import zipfile\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# import skimage.io                           #Used for imshow function\n",
    "# import skimage.transform                    #Used for resize function\n",
    "# from skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Concatenate, add\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1725042147354,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "KmChKM5_LZuP",
    "outputId": "f17ce25a-e11e-4de4-8dbc-165069ce51c8"
   },
   "outputs": [],
   "source": [
    "# dataset_dir = '/content/drive/MyDrive/Colab_Notebooks/DRIVE_Augmented/DRIVE_BioNet-Augmented'\n",
    "# os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1725042147355,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "iOZsKMJt9OLO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Dice Coefficient for evaluating segmentation models.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Dice Loss (1 - Dice Coefficient).\n",
    "    \"\"\"\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def Jaccard_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Jaccard Index (Intersection over Union - IoU).\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def Jaccard_coef_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Jaccard Loss (1 - IoU).\n",
    "    \"\"\"\n",
    "    return 1 - Jaccard_coef(y_true, y_pred)\n",
    "\n",
    "def threshold_binarize(x, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply thresholding to predictions to convert them into binary outputs.\n",
    "    \"\"\"\n",
    "    return tf.cast(x >= threshold, tf.float32)\n",
    "\n",
    "def iou(y_true, y_pred, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Intersection over Union (IoU) after thresholding y_pred.\n",
    "    \"\"\"\n",
    "    y_pred = threshold_binarize(y_pred, threshold)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Sensitivity (Recall).\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Specificity.\n",
    "    \"\"\"\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def  DiceLoss(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Dice Loss for segmentation tasks.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Ensure shape match\n",
    "    y_true_resized = tf.image.resize(y_true, (tf.shape(y_pred)[1], tf.shape(y_pred)[2]))\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_pred * y_true_resized)\n",
    "    denominator = tf.reduce_sum(y_pred**2) + tf.reduce_sum(y_true_resized**2)\n",
    "    \n",
    "    return 1 - (2. * intersection + smooth) / (denominator + smooth)\n",
    "\n",
    "def bcc_Jaccard_coef_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Combined Dice Loss and IoU Loss for better segmentation performance.\n",
    "    \"\"\"\n",
    "    iou_value = iou(y_true, y_pred, threshold=0.5)\n",
    "    return DiceLoss(y_true, y_pred) + (1 - iou_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1725042148964,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "c7eW5oZq8rMZ"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#               loss={'final_output1': DiceLoss},\n",
    "#               metrics={'final_output1': [dice_coef, iou, sensitivity, specificity]})\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2846,
     "status": "ok",
     "timestamp": 1725042151798,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "xmPrVJ8bSu6J",
    "outputId": "a4d55acc-b14e-451c-b5c5-49be29ee3946"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     model,\n",
    "#     show_shapes=False,\n",
    "#     show_dtype=False,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir='TB',\n",
    "#     expand_nested=False,\n",
    "#     dpi=46,\n",
    "#     layer_range=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as geek\n",
    "def sem_attention_block(inputs):\n",
    "    shape=inputs.shape\n",
    "    F2=Conv2D(shape[3],1, padding='same') (inputs)\n",
    "    F2=BatchNormalization() (F2)\n",
    "    F2=Activation('relu') (F2)\n",
    "    x1=MaxPooling2D(pool_size=(shape[1],shape[2]),padding='same')(F2)\n",
    "    x2=AveragePooling2D(pool_size=(shape[1],shape[2]),padding='same')(F2)\n",
    "    con1 = Concatenate()([x1,x2])\n",
    "    F3=Conv2D(shape[3],1, padding='same') (con1)\n",
    "    F3=BatchNormalization() (F3)\n",
    "    F33=Activation('relu') (F3)\n",
    "    xa=GlobalAveragePooling2D(keepdims=True)(inputs)\n",
    "    xa=Conv2D(shape[3],1, padding='same') (xa)\n",
    "    xaa=BatchNormalization() (xa)\n",
    "    xaa=Activation('sigmoid') (xaa)\n",
    "    xm=Multiply()([F33,xaa])\n",
    "    xam=Add()([inputs,xm])\n",
    "    return xam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install mamba-ssm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# -----------------------------------------------\n",
    "# FOCAL MODULATION BLOCK\n",
    "# -----------------------------------------------\n",
    "def focal_modulation(inputs, gamma=2.0, alpha=0.25):\n",
    "    num_channels = inputs.shape[-1]\n",
    "\n",
    "    mean = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_val = layers.GlobalMaxPooling2D()(inputs)\n",
    "\n",
    "    modulation = (max_val - mean) * alpha\n",
    "    modulation = layers.Reshape((1, 1, num_channels))(modulation)\n",
    "    modulation = layers.Conv2D(filters=num_channels, kernel_size=1, activation='sigmoid')(modulation)\n",
    "\n",
    "    scaled_inputs = layers.Multiply()([inputs, modulation])\n",
    "    outputs = layers.Lambda(lambda x: x ** gamma)(scaled_inputs)\n",
    "    return outputs\n",
    "\n",
    "# -----------------------------------------------\n",
    "# FOCAL MODULATION + CONTEXT AGGREGATION BLOCK\n",
    "# -----------------------------------------------\n",
    "def focal_modulation_context_aggregation(inputs, filters):\n",
    "    filters = int(filters)\n",
    "\n",
    "    conv1 = layers.Conv2D(filters, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters, kernel_size=1, activation='relu')(inputs)\n",
    "    global_context = layers.GlobalAveragePooling2D()(conv2)\n",
    "    global_context = layers.Reshape((1, 1, filters))(global_context)\n",
    "    global_context = layers.Conv2D(filters, kernel_size=1, activation='sigmoid')(global_context)\n",
    "    global_context = layers.Multiply()([conv1, global_context])\n",
    "\n",
    "    FM = focal_modulation(global_context)\n",
    "\n",
    "    concatenated = layers.Concatenate()([conv1, FM])\n",
    "    return concatenated\n",
    "\n",
    "# -----------------------------------------------\n",
    "# MAMBA-INSPIRED BLOCK\n",
    "# -----------------------------------------------\n",
    "class VisionMambaInspired(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.token_mixer = tf.keras.Sequential([\n",
    "            layers.DepthwiseConv2D(kernel_size=3, padding='same'),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "        ])\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        self.channel_mixer = tf.keras.Sequential([\n",
    "            layers.Dense(dim * 4),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(dim),\n",
    "            layers.Dropout(dropout_rate),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.token_mixer(x) + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.channel_mixer(x) + shortcut\n",
    "        return x\n",
    "\n",
    "# -----------------------------------------------\n",
    "# FINAL COMBINED BLOCK FOR BOTTLENECK\n",
    "# -----------------------------------------------\n",
    "def LiteFusion_Attention(input_tensor, filters, padding=\"same\"):\n",
    "    # Project input channels\n",
    "    input_tensor = layers.Conv2D(filters, (1, 1), padding=padding)(input_tensor)\n",
    "\n",
    "    # LayerNorm + Conv\n",
    "    x = layers.LayerNormalization()(input_tensor)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding=padding)(x)\n",
    "\n",
    "    # Context aggregation with focal modulation\n",
    "    x = focal_modulation_context_aggregation(x, filters)\n",
    "\n",
    "    # Project back to match residual shape\n",
    "    x = layers.Conv2D(filters, (1, 1), padding=padding)(x)\n",
    "\n",
    "    # Residual connection\n",
    "    out = layers.Add()([x, input_tensor])\n",
    "\n",
    "    # Vision Mamba Block\n",
    "    out = VisionMambaInspired(dim=filters)(out)\n",
    "\n",
    "    return out\n",
    "input_shape = (512,512,3)\n",
    "# inputs = layers.Input(shape=input_shape)\n",
    "# p = LiteFusion_Attention(inputs, filters=24)\n",
    "# output = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid',name = 'final_output1')(p)\n",
    "# model = models.Model(inputs=inputs, outputs=[output])\n",
    "# model = LiteFusion_Attention(inputs, filters=32)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "#  import numpy as np\n",
    "def RA_attention_block(inputs,n_classes,k):\n",
    "    shape=K.int_shape(inputs)\n",
    "    # F=Conv2D(k*n_classes,1, padding='same') (inputs)\n",
    "    F=Conv2D(k*n_classes,3, padding='same') (inputs)\n",
    "    F=BatchNormalization() (F)\n",
    "    F1=Activation('relu') (F)\n",
    "\n",
    "    F2=F1\n",
    "\n",
    "    x1=GlobalMaxPool2D()(F2)\n",
    "    x2=GlobalAveragePooling2D()(F2)\n",
    "    x = Multiply() ([x1,x2])\n",
    "    x=Reshape((n_classes,k))(x)\n",
    "    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False)) (x)\n",
    "\n",
    "    # x2=Reshape((n_classes,k)) (x)\n",
    "    # S2=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x2)\n",
    "    # S= S1+S2\n",
    "    x=Reshape((shape[1],shape[2],n_classes,k)) (F1)\n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
    "    x=Multiply()([S,x])\n",
    "    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (x)\n",
    "\n",
    "    semantic=Multiply()([inputs,M])\n",
    "    return semantic\n",
    "\n",
    "def conv_block(input, out_channels, dropout_rate=0.5):\n",
    "    # Multi-scale convolutions\n",
    "    conv1x1 = layers.Conv2D(out_channels, kernel_size=1, padding='same', use_bias=False)(input)\n",
    "    conv3x3 = layers.Conv2D(out_channels, kernel_size=3, padding='same', use_bias=False)(input)\n",
    "    conv3x3_dilated = layers.Conv2D(out_channels, kernel_size=3, padding='same', use_bias=False, dilation_rate=2)(input)\n",
    "    \n",
    "    # Fuse multi-scale outputs by summing them\n",
    "    x = conv1x1 + conv3x3 + conv3x3_dilated\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def LiteFusion_UNet(input_shape, num_classes, feature_scale=2, dropout=0.5):\n",
    "    # Define the input layer\n",
    "    filters = [int(x / feature_scale) for x in [16,32,64]]\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder - Convolutional Blocks\n",
    "    conv_block1 = conv_block(inputs, filters[0], dropout)\n",
    "#     conv_block1 = layers.Conv2D(8, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n",
    "    conv_block1 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block1)\n",
    "    conv_block1 = layers.BatchNormalization()(conv_block1)\n",
    "\n",
    "    conv_block2 = conv_block(conv_block1, filters[1], dropout)\n",
    "#     conv_block2 = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(conv_block1)\n",
    "    conv_block2 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block2)\n",
    "    conv_block2 = layers.BatchNormalization()(conv_block2)\n",
    "\n",
    "    conv_block3 = conv_block(conv_block2, filters[2], dropout)\n",
    "#     conv_block3 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(conv_block2)\n",
    "    conv_block3 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block3)\n",
    "    conv_block3 = layers.BatchNormalization()(conv_block3)\n",
    "\n",
    "    attention_output = LiteFusion_Attention(conv_block3, filters=32)\n",
    "\n",
    "\n",
    "    # Concatenate the Encoder Convolutional and Transformer blocks\n",
    "\n",
    "    att1 = RA_attention_block(attention_output,1,16)\n",
    "    fused_features = layers.Concatenate()([att1, attention_output])\n",
    "\n",
    "    # Decoder - Upsampling Blocks\n",
    "    decoder_block1 = layers.Conv2DTranspose(filters[2], kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(fused_features)\n",
    "    att2 = RA_attention_block(conv_block2,1,16)\n",
    "    decoder_block1 = layers.Concatenate()([att2, decoder_block1])\n",
    "    decoder_block1 = layers.Conv2D(filters[2], kernel_size=(3, 3), padding='same', activation='relu')(decoder_block1)\n",
    "\n",
    "    decoder_block2 = layers.Conv2DTranspose(filters[2], kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block1)\n",
    "\n",
    "    att3=RA_attention_block(conv_block1,1,16)\n",
    "    decoder_block2 = layers.Concatenate()([att3, decoder_block2])\n",
    "    decoder_block2 = layers.Conv2D(filters[2], kernel_size=(3, 3), padding='same', activation='relu')(decoder_block2)\n",
    "\n",
    "\n",
    "    decoder_block3 = layers.Conv2DTranspose(filters[0], kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block2)\n",
    "    decoder_block3 = layers.Conv2D(filters[0], kernel_size=(3, 3), padding='same', activation='relu')(decoder_block3)\n",
    "    # Decoder - Output Block\n",
    "    output = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid',name = 'final_output1')(decoder_block3)\n",
    "#     output_OD = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid', name = 'final_output2')(decoder_block3)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs=inputs, outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the input shape for binary semantic segmentation\n",
    "input_shape = (512,512,3)  # Example input shape for RGB images\n",
    "\n",
    "# Create the TransFuse Encoder-Decoder model with 3 MaxPooling layers for binary semantic segmentation\n",
    "model = LiteFusion_UNet(input_shape, 1, feature_scale=2, dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1725042151798,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "dv8QbI1YWxRq"
   },
   "outputs": [],
   "source": [
    "train_data ='' #data path\n",
    "valid_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1725042151799,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "L9t74jdEW2KO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Set the desired image dimensions\n",
    "im_height = 512\n",
    "im_width = 512\n",
    "\n",
    "# Function to get and resize train images and masks for binary segmentation\n",
    "def get_data(path):\n",
    "    # Paths to images and masks directories\n",
    "    images_paths = os.path.join(path, 'images')\n",
    "    masks_path_BV = os.path.join(path, 'GT_BV')\n",
    "\n",
    "    # Get the list of image and mask files, sorted for consistency\n",
    "    images_ids = sorted(os.listdir(images_paths))\n",
    "    mask1_ids = sorted(os.listdir(masks_path_BV))\n",
    "\n",
    "    # Initialize arrays to hold the images and masks\n",
    "    X = np.zeros((len(images_ids), im_height, im_width, 3), dtype=np.float32)  # For RGB images\n",
    "    y1 = np.zeros((len(mask1_ids), im_height, im_width, 1), dtype=np.float32)  # For binary masks\n",
    "\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n in range(len(images_ids)):\n",
    "        try:\n",
    "            # Load and resize the images\n",
    "            img = img_to_array(load_img(os.path.join(images_paths, images_ids[n]), grayscale=False))  # Load as RGB\n",
    "            x_img = resize(img, (im_height, im_width, 3), mode='constant', preserve_range=True)  # Resize image\n",
    "\n",
    "            # Load and resize the masks\n",
    "            mask_BV = img_to_array(load_img(os.path.join(masks_path_BV, mask1_ids[n]), grayscale=True))  # Load as grayscale\n",
    "            mask_BV = resize(mask_BV, (im_height, im_width, 1), mode='constant', preserve_range=True)  # Resize mask\n",
    "\n",
    "            # Normalize the image and mask values to the range [0, 1]\n",
    "            X[n] = x_img / 255.0\n",
    "            y1[n] = mask_BV / 255.0\n",
    "        except Exception as e:\n",
    "            # Handle non-image files or other loading issues\n",
    "            print(f\"Skipping file {images_ids[n]} or {mask1_ids[n]} due to an error: {e}\")\n",
    "            continue\n",
    "\n",
    "    print('Done!')\n",
    "    return X, y1\n",
    "\n",
    "# Example usage:\n",
    "# train_data = \"path_to_your_data_folder\"  # Replace with the path to your data directory\n",
    "# X, y1 = get_data(train_data)\n",
    "# print(\"X_train shape:\", X.shape)\n",
    "# print(\"y1_train shape:\", y1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57556,
     "status": "ok",
     "timestamp": 1725042209328,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "xJM1YlwwgkVl",
    "outputId": "30182eed-aa28-434a-f308-11a056a483ff"
   },
   "outputs": [],
   "source": [
    "X, y1 = get_data(train_data)\n",
    "\n",
    "print(\"X_train shape:\", X.shape)\n",
    "print(\"y1_train shape:\", y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1725042223385,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "McgJ-IH8gJIp",
    "outputId": "782be211-b171-43d6-9a89-46d469691c1f"
   },
   "outputs": [],
   "source": [
    "# prompt: ADD TRAIN TEST SPLIT AND PRINT SHAPES\n",
    "\n",
    "# Get and resize train images and masks\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y1_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y1_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1725042274511,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "Y1qWxYKCXmK2"
   },
   "outputs": [],
   "source": [
    "# prompt: convert masks into logical values and print shapes\n",
    "\n",
    "y_train = np.array(y_train > 0.5, dtype=np.uint8)\n",
    "y_test = np.array(y_test > 0.5, dtype=np.uint8)\n",
    "# y2_train_od = np.array(y2_train_od > 0.5, dtype=np.uint8)\n",
    "# y2_test_od = np.array(y2_test_od > 0.5, dtype=np.uint8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2291,
     "status": "error",
     "timestamp": 1725042328179,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "OyGrFjUOX41I",
    "outputId": "87105dcb-8f1a-46e0-9124-82d98c85ba59"
   },
   "outputs": [],
   "source": [
    "# # prompt: display masks and print unique values\n",
    "\n",
    "# ix = random.randint(0, len(X_train))\n",
    "# imshow(X_train[ix])\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(y_train[ix]))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# print(np.unique(y_train[ix]))\n",
    "# print(np.unique(y_test[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1725042341931,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "NRfvPxW8W6HW"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "nb_epoch = 300\n",
    "batch_size=16\n",
    "earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "# Append '.weights.h5' to the filename\n",
    "checkpoint = ModelCheckpoint('LiteFusion-Net_DRIVE.h5',\n",
    "                             verbose=1, save_best_only=True,save_weights_only=True)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "# model.compile(optimizer=Adam(0.002), loss=DiceLoss, metrics=['accuracy',dice_coef, Jaccard_coef,sensitivity, specificity])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=DiceLoss,  # Ensure this is a valid loss function and not None\n",
    "    metrics=['accuracy', dice_coef, Jaccard_coef]  # Ensure metrics are properly defined\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1626608,
     "status": "ok",
     "timestamp": 1725043982733,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "0YWgJOrIW8hu",
    "outputId": "bf590803-6f6f-4ec0-f99b-d6ade0ea82f1"
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    X_train,\n",
    "    y_train,  # Pass y_train directly without brackets\n",
    "    batch_size=batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, y_test)  # Pass y_test directly without brackets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the code for a single output\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "# Assuming results.history['loss'] and results.history['val_loss'] correspond to the single output loss\n",
    "plt.plot(results.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(results.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the code for a single output\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "# Assuming results.history['loss'] and results.history['val_loss'] correspond to the single output loss\n",
    "plt.plot(results.history[\"dice_coef\"], label=\"dice_coef\")\n",
    "plt.plot(results.history[\"val_dice_coef\"], label=\"Validation dice_coef\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"dice_coef\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the code for a single output\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "# Assuming results.history['loss'] and results.history['val_loss'] correspond to the single output loss\n",
    "plt.plot(results.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1725044003315,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "NDbReF2rGght"
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_test, y_pred):\n",
    "    n = y_pred.shape[0]\n",
    "    all_F1_score = np.zeros(n)\n",
    "    all_dice = np.zeros(n)\n",
    "    all_jaccard = np.zeros(n)\n",
    "    all_sensitivity = np.zeros(n)\n",
    "    all_specificity = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        gt, pred = y_test[i], y_pred[i]\n",
    "        gt_flt = np.ndarray.flatten(gt)\n",
    "        pred_flt = np.ndarray.flatten(pred)\n",
    "\n",
    "        precisions, recalls, thresholds = precision_recall_curve(gt_flt, pred_flt)\n",
    "        f1 = 2*(precisions * recalls) / (precisions + recalls)\n",
    "        max_value = np.argmax(f1)\n",
    "        thres = thresholds[max_value]\n",
    "        pred_mask = (pred_flt >= thres)\n",
    "        pred_label = pred_mask*1\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(gt_flt, pred_label).ravel()\n",
    "\n",
    "        F1_score = tp/(tp+((0.5)*(fp+fn)))\n",
    "        iou = tp / (tp + fp + fn)\n",
    "        dice = 2*tp / (2*tp + fp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        all_F1_score[i] = F1_score\n",
    "        all_dice[i] = dice\n",
    "        all_jaccard[i] = iou\n",
    "        all_sensitivity[i] = recall\n",
    "        all_specificity[i] = specificity\n",
    "\n",
    "        print(' F1_score: {:4f}, Dice: {:4f}, Jaccard: {:4f}, Sensitivity: {:4f}, Specificity: {:4f}'.format(\n",
    "        np.nanmean(all_F1_score), np.nanmean(all_dice), np.nanmean(all_jaccard), np.nanmean(all_sensitivity), np.nanmean(all_specificity)\n",
    "        ))\n",
    "    return all_F1_score, all_dice, all_jaccard, all_sensitivity, all_specificity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1725042209330,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "ihWhyLM4j0TC"
   },
   "outputs": [],
   "source": [
    "# model.save_weights('/homes/imransharif/Mehwish/DRIVE/AV_weights/FR_UNet_RAAM_DRIVE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3819,
     "status": "ok",
     "timestamp": 1725044013218,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "5R9Hw2AkqHjG",
    "outputId": "f84fbb34-4253-424b-bec4-b56329779b56"
   },
   "outputs": [],
   "source": [
    "# valid_data = '/content/ISIC2018_256x256/test' #data path\n",
    "X_test, y_test = get_data(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1725044862387,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "cj-CElS6ru_a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def evaluate_metrics(y_test, y_pred, return_mode='all'):\n",
    "    n = y_pred.shape[0]\n",
    "    all_accuracy = np.zeros(n)\n",
    "    all_dice = np.zeros(n)\n",
    "    all_jaccard = np.zeros(n)\n",
    "    all_sensitivity = np.zeros(n)\n",
    "    all_specificity = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        gt, pred = y_test[i], y_pred[i]\n",
    "        gt_flt = np.ndarray.flatten(gt)\n",
    "        pred_flt = np.ndarray.flatten(pred)\n",
    "\n",
    "        precisions, recalls, thresholds = precision_recall_curve(gt_flt, pred_flt)\n",
    "        f1 = 2*(precisions * recalls) / (precisions + recalls)\n",
    "        max_value = np.argmax(f1)\n",
    "        precision, recall, thres = precisions[max_value], recalls[max_value], thresholds[max_value]\n",
    "\n",
    "        maxval = 255\n",
    "        pred_mask = (pred_flt > thres)\n",
    "        pred_label = pred_mask*1\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(gt_flt, pred_label).ravel()\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        iou = tp / (tp + fp + fn)\n",
    "        dice = 2*tp / (2*tp + fp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        all_accuracy[i] = accuracy\n",
    "        all_dice[i] = dice\n",
    "        all_jaccard[i] = iou\n",
    "        all_sensitivity[i] = recall\n",
    "        all_specificity[i] = specificity\n",
    "\n",
    "    print('Accuracy: {:4f}, Dice: {:4f}, Jaccard: {:4f}, Sensitivity: {:4f}, Specificity: {:4f}'.format(\n",
    "        np.nanmean(all_accuracy), np.nanmean(all_dice), np.nanmean(all_jaccard), np.nanmean(all_sensitivity), np.nanmean(all_specificity)\n",
    "    ))\n",
    "    if return_mode == 'all':\n",
    "        return all_accuracy, all_dice, all_jaccard, all_sensitivity, all_specificity\n",
    "    if return_mode == 'value':\n",
    "        return np.nanmean(all_accuracy), np.nanmean(all_dice), np.nanmean(all_jaccard), np.nanmean(all_sensitivity), np.nanmean(all_specificity)\n",
    "    else:\n",
    "        return 'No val returned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2587,
     "status": "ok",
     "timestamp": 1725045045162,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "bT-hrleO3M3c",
    "outputId": "07f38fcd-bcbf-461c-83f9-d3972cae3e5a"
   },
   "outputs": [],
   "source": [
    "# Convert ground truth labels to binary\n",
    "y_test_BV = (y_test[0] > 0.5).astype(np.uint8)\n",
    "# y_test_OD = (y_test[1] > 0.5).astype(np.uint8)\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size =1 ,verbose=1)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# evl = evaluate_metrics(y_test_BV, y_pred, return_mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1725044188555,
     "user": {
      "displayName": "mehwish mehmood",
      "userId": "03028843311539350970"
     },
     "user_tz": -300
    },
    "id": "Bm5tHx6E6Y_1"
   },
   "outputs": [],
   "source": [
    "# Convert model's outputs to binary\n",
    "predictions_BV = (y_pred[0] > 0.5).astype(np.uint8)\n",
    "# predictions_OD = (predictions[1] > 0.5).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage = model.count_params() * 4  # Assuming float32 data type (4 bytes per parameter)\n",
    "print(\"Memory Usage: {:.2f} MB\".format(memory_usage / 1024 / 1024))  # Divide by 1024 twice to convert from bytes to KB, then KB to MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   !pip install keras-flops\n",
    "  from keras_flops import get_flops\n",
    "\n",
    "  flops = get_flops(model)\n",
    "  print(f\"FLOPs: {flops / 10**9:.03} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pampc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
