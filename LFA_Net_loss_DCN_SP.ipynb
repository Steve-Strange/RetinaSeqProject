{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:27.187106Z",
     "iopub.status.busy": "2025-12-26T10:17:27.186304Z",
     "iopub.status.idle": "2025-12-26T10:17:38.866947Z",
     "shell.execute_reply": "2025-12-26T10:17:38.866281Z",
     "shell.execute_reply.started": "2025-12-26T10:17:27.187068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n",
      "Train: 20 - 20\n",
      "Test: 20 - 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.28it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 54.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"config.py\"):\n",
    "    print(\"Warning: Found 'config.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "if os.path.exists(\"torch.py\"):\n",
    "    print(\"Warning: Found 'torch.py' in the current directory. Please rename it to avoid conflicts with torch.\")\n",
    "\n",
    "# 优先导入 torch\n",
    "import torch\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast, RandomCrop, RandomRotate90, RandomGridShuffle\n",
    "\n",
    "\"\"\" Create a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "'''加载数据：原图+标签'''\n",
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "'''\n",
    "增强数据\n",
    "对图像及其对应mask数据增强\n",
    "'''\n",
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    size = (560, 560)\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(os.sep)[-1].split(\".\")[0]\n",
    "        \n",
    "        \"\"\" Reading image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "\n",
    "        if x is None or y is None:\n",
    "            print(f\"Error reading image or mask for {name}\")\n",
    "            continue\n",
    "\n",
    "        if augment == True:\n",
    "            transformations = [\n",
    "                HorizontalFlip(p=1.0),\n",
    "                VerticalFlip(p=1.0),\n",
    "                Rotate(limit=45, p=1.0),\n",
    "                RandomBrightnessContrast(p=0.6),\n",
    "                RandomCrop(300, 300, p=0.8),\n",
    "                RandomRotate90(p=1.0),\n",
    "                RandomGridShuffle(p=0.7)\n",
    "            ]\n",
    "\n",
    "            augmented_images = [x]\n",
    "            augmented_masks = [y]\n",
    "\n",
    "            for aug in transformations:\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                augmented_images.append(augmented[\"image\"])\n",
    "                augmented_masks.append(augmented[\"mask\"])\n",
    "            \n",
    "            X = augmented_images\n",
    "            Y = augmented_masks\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            #将图像和掩码调整到目标大小\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            tmp_image_name = f\"{name}_{index}.png\"\n",
    "            tmp_mask_name = f\"{name}_{index}.png\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Load the data \"\"\"\n",
    "    # 修改为相对路径\n",
    "    data_path = \"data/DRIVE/\"\n",
    "    \n",
    "    if os.path.exists(data_path):\n",
    "        (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
    "\n",
    "        print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "        print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "        \"\"\" Create directories to save the augmented data \"\"\"\n",
    "        create_dir(\"working/new_data/train/image/\")\n",
    "        create_dir(\"working/new_data/train/mask/\")\n",
    "        create_dir(\"working/new_data/test/image/\")\n",
    "        create_dir(\"working/new_data/test/mask/\")\n",
    "\n",
    "        \"\"\" Data augmentation \"\"\"\n",
    "        # 取消注释以运行数据增强\n",
    "        augment_data(train_x, train_y, \"working/new_data/train/\", augment=True)\n",
    "        augment_data(test_x, test_y, \"working/new_data/test/\", augment=False)\n",
    "    else:\n",
    "        print(f\"Data path not found: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:38.868551Z",
     "iopub.status.busy": "2025-12-26T10:17:38.868200Z",
     "iopub.status.idle": "2025-12-26T10:17:40.435461Z",
     "shell.execute_reply": "2025-12-26T10:17:40.434747Z",
     "shell.execute_reply.started": "2025-12-26T10:17:38.868526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape (DCN + StripPooling): torch.Size([2, 1, 560, 560])\n"
     ]
    }
   ],
   "source": [
    "# Model Structure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.ops as ops # 需要 torchvision >= 0.9.0\n",
    "\n",
    "# --- 创新模块 1: Strip Pooling (SPM) ---\n",
    "# 专门针对细长结构（如血管、车道线）设计的池化模块\n",
    "# 论文来源: CVPR 2020 \"SPNet: Strip Pooling Network\"\n",
    "class StripPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_size, norm_layer=nn.BatchNorm2d):\n",
    "        super(StripPooling, self).__init__()\n",
    "        self.pool1 = nn.AdaptiveAvgPool2d((pool_size[0], 1)) # H方向条纹\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((1, pool_size[1])) # W方向条纹\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        inter_channels = int(in_channels/4)\n",
    "        self.conv1_1 = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv1_2 = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_0 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, 3, 1, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_1 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, 3, 1, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_2 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, 3, 1, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_3 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, (1, 3), 1, (0, 1), bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_4 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, (3, 1), 1, (1, 0), bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_5 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, 3, 1, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv2_6 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, 3, 1, 1, bias=False), norm_layer(inter_channels), nn.ReLU(True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(inter_channels*2, in_channels, 1, bias=False), norm_layer(in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        x1 = self.conv1_1(x)\n",
    "        x2 = self.conv1_2(x)\n",
    "        x2_1 = self.conv2_0(x1)\n",
    "        x2_2 = self.conv2_1(x2)\n",
    "        x2_3 = self.conv2_2(x1 + x2)\n",
    "        x2_4 = self.conv2_3(x1 + x2)\n",
    "        x2_5 = self.conv2_4(x1 + x2)\n",
    "        x2_6 = self.conv2_5(x1 + x2)\n",
    "        x2_7 = self.conv2_6(x1 + x2)\n",
    "        x1 = self.pool1(x1)\n",
    "        x1 = F.interpolate(x1, (h, w), mode=\"bilinear\", align_corners=True)\n",
    "        x2 = self.pool2(x2)\n",
    "        x2 = F.interpolate(x2, (h, w), mode=\"bilinear\", align_corners=True)\n",
    "        out = self.conv3(torch.cat([x1, x2], dim=1))\n",
    "        return F.relu(x + out)\n",
    "\n",
    "# --- 创新模块 2: Deformable Conv Block ---\n",
    "# 使用 torchvision 的可变形卷积替代普通卷积\n",
    "class DeformConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DeformConvBlock, self).__init__()\n",
    "        \n",
    "        # 1. 偏移量生成器 (Offset Generator)\n",
    "        # 输入特征 -> 输出偏移量 (2 * kernel_height * kernel_width)\n",
    "        self.offset_conv = nn.Conv2d(in_channels, 2 * 3 * 3, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 2. 可变形卷积 (DeformConv2d)\n",
    "        self.dcn = ops.DeformConv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 匹配维度用于残差连接\n",
    "        self.proj = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算偏移量\n",
    "        offset = self.offset_conv(x)\n",
    "        \n",
    "        # 执行可变形卷积\n",
    "        out = self.dcn(x, offset)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out + self.proj(x)\n",
    "\n",
    "# --- 基础模块 (保持原有的 Attention 和 Mamba 概念) ---\n",
    "class VisionMambaInspired(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.1):\n",
    "        super(VisionMambaInspired, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.token_mixer = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.channel_mixer = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        shortcut = x\n",
    "        x_perm = x.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm1(x_perm).permute(0, 3, 1, 2)\n",
    "        x_tm = self.token_mixer(x_norm) + shortcut\n",
    "        shortcut = x_tm\n",
    "        x_perm = x_tm.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm2(x_perm)\n",
    "        x_cm = self.channel_mixer(x_norm)\n",
    "        x_cm = x_cm.permute(0, 3, 1, 2)\n",
    "        return x_cm + shortcut\n",
    "\n",
    "class LiteFusionAttention(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(LiteFusionAttention, self).__init__()\n",
    "        self.proj1 = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(filters)\n",
    "        self.conv = nn.Conv2d(filters, filters, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 这里我们加入 Strip Pooling 来增强长条形特征提取\n",
    "        self.strip_pool = StripPooling(filters, (20, 12)) \n",
    "        \n",
    "        self.proj2 = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.vm = VisionMambaInspired(filters)\n",
    "        self.res_proj = nn.Conv2d(in_channels, filters, kernel_size=1) if in_channels != filters else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = self.proj1(x)\n",
    "        x_perm = input_tensor.permute(0, 2, 3, 1)\n",
    "        x_norm = self.norm(x_perm).permute(0, 3, 1, 2)\n",
    "        \n",
    "        # 卷积 -> Strip Pooling -> Mamba\n",
    "        x_conv = self.conv(x_norm)\n",
    "        x_sp = self.strip_pool(x_conv) \n",
    "        x_proj = self.proj2(x_sp)\n",
    "        \n",
    "        res = self.res_proj(x) if isinstance(self.res_proj, nn.Conv2d) else input_tensor\n",
    "        out = x_proj + res\n",
    "        out = self.vm(out)\n",
    "        return out\n",
    "\n",
    "class RA_AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, k):\n",
    "        super(RA_AttentionBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.conv = nn.Conv2d(in_channels, k * n_classes, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(k * n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        f = self.relu(self.bn(self.conv(x)))\n",
    "        x1 = self.gmp(f)\n",
    "        x2 = self.gap(f)\n",
    "        x_mul = x1 * x2\n",
    "        x_reshape = x_mul.view(b, self.n_classes, self.k)\n",
    "        s = torch.mean(x_reshape, dim=-1, keepdim=False)\n",
    "        f_perm = f.permute(0, 2, 3, 1)\n",
    "        f_reshape = f_perm.view(b, h, w, self.n_classes, self.k)\n",
    "        f_mean = torch.mean(f_reshape, dim=-1, keepdim=False)\n",
    "        s_expanded = s.view(b, 1, 1, self.n_classes)\n",
    "        x_weighted = f_mean * s_expanded\n",
    "        m = torch.mean(x_weighted, dim=-1, keepdim=True)\n",
    "        m = m.permute(0, 3, 1, 2)\n",
    "        semantic = x * m\n",
    "        return semantic\n",
    "\n",
    "# --- 主模型架构 ---\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=1, feature_scale=2, dropout=0.5):\n",
    "        super(build_unet, self).__init__()\n",
    "        filters = [int(x / feature_scale) for x in [16, 32, 64]]\n",
    "        \n",
    "        # Encoder: 使用 DeformConvBlock 替代普通 ConvBlock\n",
    "        # DCN 能自适应血管的弯曲形状\n",
    "        self.conv1 = DeformConvBlock(input_channels, filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = DeformConvBlock(filters[0], filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = DeformConvBlock(filters[1], filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck: 包含 Strip Pooling 的 LiteFusionAttention\n",
    "        self.lfa = LiteFusionAttention(filters[2], filters=32)\n",
    "        \n",
    "        lfa_out_channels = 32 \n",
    "        self.att1 = RA_AttentionBlock(lfa_out_channels, 1, 16)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(lfa_out_channels * 2, filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att2 = RA_AttentionBlock(filters[1], 1, 16)\n",
    "        self.dec_conv1 = nn.Conv2d(filters[1] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.att3 = RA_AttentionBlock(filters[0], 1, 16)\n",
    "        self.dec_conv2 = nn.Conv2d(filters[0] + filters[2], filters[2], kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(filters[2], filters[0], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_conv3 = nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.final = nn.Conv2d(filters[0], num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder (DCN)\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        \n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        \n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "        \n",
    "        # Bottleneck (Strip Pooling inside)\n",
    "        lfa = self.lfa(p3)\n",
    "        \n",
    "        # Decoder\n",
    "        att1 = self.att1(lfa)\n",
    "        fused = torch.cat([att1, lfa], dim=1)\n",
    "        \n",
    "        d1 = self.up1(fused)\n",
    "        if d1.size() != c2.size():\n",
    "             d1 = F.interpolate(d1, size=c2.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        att2 = self.att2(c2)\n",
    "        d1 = torch.cat([att2, d1], dim=1)\n",
    "        d1 = self.relu1(self.dec_conv1(d1))\n",
    "        \n",
    "        d2 = self.up2(d1)\n",
    "        if d2.size() != c1.size():\n",
    "             d2 = F.interpolate(d2, size=c1.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        att3 = self.att3(c1)\n",
    "        d2 = torch.cat([att3, d2], dim=1)\n",
    "        d2 = self.relu2(self.dec_conv2(d2))\n",
    "        \n",
    "        d3 = self.up3(d2)\n",
    "        if d3.size() != x.size():\n",
    "             d3 = F.interpolate(d3, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "             \n",
    "        d3 = self.relu3(self.dec_conv3(d3))\n",
    "        \n",
    "        out = self.final(d3)\n",
    "        return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试一下 DCN 和 Strip Pooling 是否能跑通\n",
    "    x = torch.randn((2, 3, 560, 560)) # 回到 3 通道输入\n",
    "    f = build_unet(input_channels=3)\n",
    "    y = f(x)\n",
    "    print(f\"Output shape (DCN + StripPooling): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.437315Z",
     "iopub.status.busy": "2025-12-26T10:17:40.437071Z",
     "iopub.status.idle": "2025-12-26T10:17:40.443522Z",
     "shell.execute_reply": "2025-12-26T10:17:40.442839Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.437294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image/255.0 ## (512, 512, 3)\n",
    "        image = np.transpose(image, (2, 0, 1))  ## (3, 512, 512)\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask/255.0   ## (512, 512)\n",
    "        mask = np.expand_dims(mask, axis=0) ## (1, 512, 512)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.445318Z",
     "iopub.status.busy": "2025-12-26T10:17:40.445100Z",
     "iopub.status.idle": "2025-12-26T10:17:40.467440Z",
     "shell.execute_reply": "2025-12-26T10:17:40.466743Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.445297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Tversky Loss\n",
    "    特别适合类别极不平衡 + 微结构（血管）\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, smooth=1e-6):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        TP = (inputs * targets).sum()\n",
    "        FP = ((1 - targets) * inputs).sum()\n",
    "        FN = (targets * (1 - inputs)).sum()\n",
    "\n",
    "        tversky = (TP + self.smooth) / (\n",
    "            TP + self.alpha * FP + self.beta * FN + self.smooth\n",
    "        )\n",
    "\n",
    "        loss = torch.pow((1 - tversky), self.gamma)\n",
    "        return loss\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Boundary Loss via distance transform\n",
    "    强制预测边界贴近 GT 边界\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BoundaryLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        # 计算边界（简单 Sobel）\n",
    "        def get_boundary(x):\n",
    "            sobel_x = torch.tensor([[1, 0, -1],\n",
    "                                    [2, 0, -2],\n",
    "                                    [1, 0, -1]], device=x.device).float()\n",
    "            sobel_y = sobel_x.t()\n",
    "\n",
    "            sobel_x = sobel_x.view(1, 1, 3, 3)\n",
    "            sobel_y = sobel_y.view(1, 1, 3, 3)\n",
    "\n",
    "            grad_x = F.conv2d(x, sobel_x, padding=1)\n",
    "            grad_y = F.conv2d(x, sobel_y, padding=1)\n",
    "\n",
    "            return torch.sqrt(grad_x ** 2 + grad_y ** 2 + 1e-6)\n",
    "\n",
    "        pred_boundary = get_boundary(inputs)\n",
    "        gt_boundary = get_boundary(targets)\n",
    "\n",
    "        return F.l1_loss(pred_boundary, gt_boundary)\n",
    "\n",
    "class VesselSegmentationLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    最终联合损失：\n",
    "    Focal Tversky + Boundary\n",
    "    \"\"\"\n",
    "    def __init__(self, w_tversky=1.0, w_boundary=0.1):\n",
    "        super(VesselSegmentationLoss, self).__init__()\n",
    "        self.tversky = FocalTverskyLoss()\n",
    "        self.boundary = BoundaryLoss()\n",
    "        self.w_tversky = w_tversky\n",
    "        self.w_boundary = w_boundary\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        loss_t = self.tversky(inputs, targets)\n",
    "        loss_b = self.boundary(inputs, targets)\n",
    "        return self.w_tversky * loss_t + self.w_boundary * loss_b\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.468545Z",
     "iopub.status.busy": "2025-12-26T10:17:40.468339Z",
     "iopub.status.idle": "2025-12-26T10:17:40.482989Z",
     "shell.execute_reply": "2025-12-26T10:17:40.482370Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.468525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\"\"\" Seeding the randomness. \"\"\"\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\" Create a directory. \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Calculate the time taken \"\"\"\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:17:40.483887Z",
     "iopub.status.busy": "2025-12-26T10:17:40.483664Z",
     "iopub.status.idle": "2025-12-26T10:56:04.787586Z",
     "shell.execute_reply": "2025-12-26T10:56:04.786752Z",
     "shell.execute_reply.started": "2025-12-26T10:17:40.483865Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train: 160 - Valid: 20\n",
      "\n",
      "Valid loss improved from inf to 0.9497. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.947\n",
      "\t Val. Loss: 0.950\n",
      "\n",
      "Valid loss improved from 0.9497 to 0.9497. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.946\n",
      "\t Val. Loss: 0.950\n",
      "\n",
      "Valid loss improved from 0.9497 to 0.9496. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.942\n",
      "\t Val. Loss: 0.950\n",
      "\n",
      "Valid loss improved from 0.9496 to 0.9495. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.936\n",
      "\t Val. Loss: 0.950\n",
      "\n",
      "Valid loss improved from 0.9495 to 0.9474. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.931\n",
      "\t Val. Loss: 0.947\n",
      "\n",
      "Valid loss improved from 0.9474 to 0.9459. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.926\n",
      "\t Val. Loss: 0.946\n",
      "\n",
      "Valid loss improved from 0.9459 to 0.9309. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.915\n",
      "\t Val. Loss: 0.931\n",
      "\n",
      "Valid loss improved from 0.9309 to 0.9147. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.908\n",
      "\t Val. Loss: 0.915\n",
      "\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.899\n",
      "\t Val. Loss: 0.948\n",
      "\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.877\n",
      "\t Val. Loss: 0.959\n",
      "\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.836\n",
      "\t Val. Loss: 1.036\n",
      "\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.788\n",
      "\t Val. Loss: 1.037\n",
      "\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.724\n",
      "\t Val. Loss: 1.037\n",
      "\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.682\n",
      "\t Val. Loss: 1.027\n",
      "\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.662\n",
      "\t Val. Loss: 1.036\n",
      "\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.630\n",
      "\t Val. Loss: 1.027\n",
      "\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.590\n",
      "\t Val. Loss: 1.030\n",
      "\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.570\n",
      "\t Val. Loss: 0.947\n",
      "\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.538\n",
      "\t Val. Loss: 0.922\n",
      "\n",
      "Valid loss improved from 0.9147 to 0.8490. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.523\n",
      "\t Val. Loss: 0.849\n",
      "\n",
      "Valid loss improved from 0.8490 to 0.7718. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.508\n",
      "\t Val. Loss: 0.772\n",
      "\n",
      "Valid loss improved from 0.7718 to 0.7077. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.493\n",
      "\t Val. Loss: 0.708\n",
      "\n",
      "Valid loss improved from 0.7077 to 0.5938. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.481\n",
      "\t Val. Loss: 0.594\n",
      "\n",
      "Valid loss improved from 0.5938 to 0.5726. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.466\n",
      "\t Val. Loss: 0.573\n",
      "\n",
      "Valid loss improved from 0.5726 to 0.5415. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.459\n",
      "\t Val. Loss: 0.541\n",
      "\n",
      "Valid loss improved from 0.5415 to 0.5131. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.458\n",
      "\t Val. Loss: 0.513\n",
      "\n",
      "Valid loss improved from 0.5131 to 0.5116. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 27 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.445\n",
      "\t Val. Loss: 0.512\n",
      "\n",
      "Valid loss improved from 0.5116 to 0.4499. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 28 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.442\n",
      "\t Val. Loss: 0.450\n",
      "\n",
      "Epoch: 29 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.435\n",
      "\t Val. Loss: 0.467\n",
      "\n",
      "Valid loss improved from 0.4499 to 0.4187. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 30 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.428\n",
      "\t Val. Loss: 0.419\n",
      "\n",
      "Epoch: 31 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.437\n",
      "\t Val. Loss: 0.426\n",
      "\n",
      "Valid loss improved from 0.4187 to 0.4173. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 32 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.424\n",
      "\t Val. Loss: 0.417\n",
      "\n",
      "Valid loss improved from 0.4173 to 0.4086. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 33 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.413\n",
      "\t Val. Loss: 0.409\n",
      "\n",
      "Valid loss improved from 0.4086 to 0.4003. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 34 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.412\n",
      "\t Val. Loss: 0.400\n",
      "\n",
      "Valid loss improved from 0.4003 to 0.3962. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 35 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.409\n",
      "\t Val. Loss: 0.396\n",
      "\n",
      "Epoch: 36 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.406\n",
      "\t Val. Loss: 0.397\n",
      "\n",
      "Valid loss improved from 0.3962 to 0.3930. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 37 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.403\n",
      "\t Val. Loss: 0.393\n",
      "\n",
      "Valid loss improved from 0.3930 to 0.3891. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 38 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.398\n",
      "\t Val. Loss: 0.389\n",
      "\n",
      "Valid loss improved from 0.3891 to 0.3829. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 39 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.397\n",
      "\t Val. Loss: 0.383\n",
      "\n",
      "Valid loss improved from 0.3829 to 0.3810. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 40 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.392\n",
      "\t Val. Loss: 0.381\n",
      "\n",
      "Epoch: 41 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.394\n",
      "\t Val. Loss: 0.381\n",
      "\n",
      "Valid loss improved from 0.3810 to 0.3801. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 42 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.389\n",
      "\t Val. Loss: 0.380\n",
      "\n",
      "Epoch: 43 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.388\n",
      "\t Val. Loss: 0.381\n",
      "\n",
      "Valid loss improved from 0.3801 to 0.3749. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 44 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.391\n",
      "\t Val. Loss: 0.375\n",
      "\n",
      "Valid loss improved from 0.3749 to 0.3747. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 45 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.389\n",
      "\t Val. Loss: 0.375\n",
      "\n",
      "Valid loss improved from 0.3747 to 0.3744. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 46 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.384\n",
      "\t Val. Loss: 0.374\n",
      "\n",
      "Epoch: 47 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.385\n",
      "\t Val. Loss: 0.381\n",
      "\n",
      "Valid loss improved from 0.3744 to 0.3710. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 48 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.383\n",
      "\t Val. Loss: 0.371\n",
      "\n",
      "Epoch: 49 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.383\n",
      "\t Val. Loss: 0.371\n",
      "\n",
      "Epoch: 50 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.386\n",
      "\t Val. Loss: 0.377\n",
      "\n",
      "Epoch: 51 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.379\n",
      "\t Val. Loss: 0.372\n",
      "\n",
      "Valid loss improved from 0.3710 to 0.3697. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 52 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.378\n",
      "\t Val. Loss: 0.370\n",
      "\n",
      "Valid loss improved from 0.3697 to 0.3677. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 53 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.379\n",
      "\t Val. Loss: 0.368\n",
      "\n",
      "Epoch: 54 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.378\n",
      "\t Val. Loss: 0.369\n",
      "\n",
      "Epoch: 55 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.376\n",
      "\t Val. Loss: 0.368\n",
      "\n",
      "Epoch: 56 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.376\n",
      "\t Val. Loss: 0.368\n",
      "\n",
      "Epoch: 57 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.374\n",
      "\t Val. Loss: 0.371\n",
      "\n",
      "Epoch: 58 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.376\n",
      "\t Val. Loss: 0.379\n",
      "\n",
      "Valid loss improved from 0.3677 to 0.3655. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 59 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.375\n",
      "\t Val. Loss: 0.365\n",
      "\n",
      "Epoch: 60 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.376\n",
      "\t Val. Loss: 0.380\n",
      "\n",
      "Valid loss improved from 0.3655 to 0.3642. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 61 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.375\n",
      "\t Val. Loss: 0.364\n",
      "\n",
      "Epoch: 62 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.373\n",
      "\t Val. Loss: 0.366\n",
      "\n",
      "Epoch: 63 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.371\n",
      "\t Val. Loss: 0.368\n",
      "\n",
      "Valid loss improved from 0.3642 to 0.3638. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 64 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.370\n",
      "\t Val. Loss: 0.364\n",
      "\n",
      "Valid loss improved from 0.3638 to 0.3610. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 65 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.368\n",
      "\t Val. Loss: 0.361\n",
      "\n",
      "Epoch: 66 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.369\n",
      "\t Val. Loss: 0.361\n",
      "\n",
      "Epoch: 67 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.370\n",
      "\t Val. Loss: 0.388\n",
      "\n",
      "Epoch: 68 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.370\n",
      "\t Val. Loss: 0.368\n",
      "\n",
      "Epoch: 69 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.369\n",
      "\t Val. Loss: 0.367\n",
      "\n",
      "Epoch: 70 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.368\n",
      "\t Val. Loss: 0.361\n",
      "\n",
      "Epoch: 71 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.366\n",
      "\t Val. Loss: 0.370\n",
      "\n",
      "Valid loss improved from 0.3610 to 0.3595. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 72 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.367\n",
      "\t Val. Loss: 0.360\n",
      "\n",
      "Valid loss improved from 0.3595 to 0.3591. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 73 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.366\n",
      "\t Val. Loss: 0.359\n",
      "\n",
      "Epoch: 74 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.364\n",
      "\t Val. Loss: 0.370\n",
      "\n",
      "Valid loss improved from 0.3591 to 0.3584. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 75 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.365\n",
      "\t Val. Loss: 0.358\n",
      "\n",
      "Epoch: 76 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.363\n",
      "\t Val. Loss: 0.361\n",
      "\n",
      "Epoch: 77 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.363\n",
      "\t Val. Loss: 0.366\n",
      "\n",
      "Epoch: 78 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.366\n",
      "\t Val. Loss: 0.360\n",
      "\n",
      "Epoch: 79 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.364\n",
      "\t Val. Loss: 0.375\n",
      "\n",
      "Valid loss improved from 0.3584 to 0.3579. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 80 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.361\n",
      "\t Val. Loss: 0.358\n",
      "\n",
      "Valid loss improved from 0.3579 to 0.3540. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 81 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.362\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Epoch: 82 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.361\n",
      "\t Val. Loss: 0.380\n",
      "\n",
      "Valid loss improved from 0.3540 to 0.3539. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 83 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.362\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Epoch: 84 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.359\n",
      "\t Val. Loss: 0.356\n",
      "\n",
      "Valid loss improved from 0.3539 to 0.3537. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 85 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.359\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Epoch: 86 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.360\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Valid loss improved from 0.3537 to 0.3534. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 87 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.360\n",
      "\t Val. Loss: 0.353\n",
      "\n",
      "Epoch: 88 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.358\n",
      "\t Val. Loss: 0.377\n",
      "\n",
      "Valid loss improved from 0.3534 to 0.3530. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 89 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.357\n",
      "\t Val. Loss: 0.353\n",
      "\n",
      "Epoch: 90 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.357\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Epoch: 91 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.358\n",
      "\t Val. Loss: 0.354\n",
      "\n",
      "Valid loss improved from 0.3530 to 0.3510. Saving checkpoint: working/files/drive_checkpoint_loss.pth\n",
      "Epoch: 92 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.357\n",
      "\t Val. Loss: 0.351\n",
      "\n",
      "Epoch: 93 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.355\n",
      "\t Val. Loss: 0.351\n",
      "\n",
      "Epoch: 94 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.355\n",
      "\t Val. Loss: 0.357\n",
      "\n",
      "Epoch: 95 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.356\n",
      "\t Val. Loss: 0.357\n",
      "\n",
      "Epoch: 96 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.354\n",
      "\t Val. Loss: 0.353\n",
      "\n",
      "Epoch: 97 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.353\n",
      "\t Val. Loss: 0.352\n",
      "\n",
      "Epoch: 98 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.353\n",
      "\t Val. Loss: 0.363\n",
      "\n",
      "Epoch: 99 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.352\n",
      "\t Val. Loss: 0.358\n",
      "\n",
      "Epoch: 100 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.353\n",
      "\t Val. Loss: 0.356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# from data import DriveDataset\n",
    "# from model import build_unet\n",
    "# from loss import DiceLoss, DiceBCELoss\n",
    "# from utils import seeding, create_dir, epoch_time\n",
    "\n",
    "'''训练深度学习模型'''\n",
    "def train(model, loader, optimizer, loss_fn, device, show_images=False):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        # if i == 1 and show_images:\n",
    "        #    # 显示第一批图像和掩码\n",
    "        #     img = x[0].cpu().numpy()  # 假设图像是CHW格式\n",
    "        #     img = np.transpose(img, (1, 2, 0))  # 转换为HWC格式\n",
    "        #     img = img[..., ::-1]  # 将BGR转换为RGB\n",
    "        #     mask = y[0].cpu().numpy()  # 假设掩码是CHW格式\n",
    "        #     mask = np.transpose(mask, (1, 2, 0))  # 转换为HWC格式\n",
    "\n",
    "        #     plt.figure(figsize=(12, 6))\n",
    "\n",
    "        #     plt.subplot(1, 2, 1)\n",
    "        #     plt.imshow(img)\n",
    "        #     plt.title(\"Sample Image\")\n",
    "\n",
    "        #     plt.subplot(1, 2, 2)\n",
    "        #     plt.imshow(mask, cmap='gray')\n",
    "        #     plt.title(\"Corresponding Mask\")\n",
    "\n",
    "        #     plt.show()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    #计算整个epoch的平均损失\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Directories \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    train_x = sorted(glob(\"working/new_data/train/image/*\"))\n",
    "    train_y = sorted(glob(\"working/new_data/train/mask/*\"))\n",
    "\n",
    "    valid_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    valid_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "\n",
    "    data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\n",
    "    print(data_str)\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (H, W)\n",
    "    batch_size = 64\n",
    "    num_epochs = 100   \n",
    "    lr = 1e-3\n",
    "    checkpoint_path = \"working/files/drive_checkpoint_loss.pth\"\n",
    "\n",
    "    \"\"\" Dataset and loader \"\"\"\n",
    "    train_dataset = DriveDataset(train_x, train_y)\n",
    "    valid_dataset = DriveDataset(valid_x, valid_y)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   ## GTX 1060 6GB\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "    # loss_fn = DiceBCELoss()\n",
    "    \n",
    "    loss_fn = VesselSegmentationLoss(\n",
    "        w_tversky=1.0,\n",
    "        w_boundary=0.1\n",
    "    )\n",
    "\n",
    "\n",
    "    \"\"\" Training the model \"\"\"\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        #该轮训练的平均损失值 train_loss\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device, show_images=True)\n",
    "        #返回验证损失 valid_loss\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        \"\"\" Saving the model \"\"\"\n",
    "        if valid_loss < best_valid_loss:\n",
    "            data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
    "        data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
    "        data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
    "        print(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T10:56:04.789919Z",
     "iopub.status.busy": "2025-12-26T10:56:04.789291Z",
     "iopub.status.idle": "2025-12-26T10:56:09.112965Z",
     "shell.execute_reply": "2025-12-26T10:56:09.112196Z",
     "shell.execute_reply.started": "2025-12-26T10:56:04.789886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_874619/1244756369.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
      "  0%|          | 0/20 [00:00<?, ?it/s][ WARN:0@419.692] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
      " 15%|█▌        | 3/20 [00:00<00:01, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.6518, f1:0.7892,recall:0.7624,precision:0.818,acc:0.9638,specificity:0.983\n",
      ":-- jaccard:0.6836, f1:0.8121,recall:0.7433,precision:0.895,acc:0.9649,specificity:0.990\n",
      ":-- jaccard:0.4819, f1:0.6504,recall:0.5065,precision:0.908,acc:0.9458,specificity:0.994\n",
      ":-- jaccard:0.6553, f1:0.7918,recall:0.7337,precision:0.860,acc:0.9646,specificity:0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:00<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.5863, f1:0.7392,recall:0.6115,precision:0.934,acc:0.9597,specificity:0.996\n",
      ":-- jaccard:0.5907, f1:0.7427,recall:0.6376,precision:0.889,acc:0.9571,specificity:0.991\n",
      ":-- jaccard:0.6003, f1:0.7502,recall:0.6750,precision:0.844,acc:0.9589,specificity:0.987\n",
      ":-- jaccard:0.5468, f1:0.7070,recall:0.5967,precision:0.867,acc:0.9578,specificity:0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:00<00:00, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.5720, f1:0.7277,recall:0.6144,precision:0.892,acc:0.9627,specificity:0.993\n",
      ":-- jaccard:0.6210, f1:0.7662,recall:0.6889,precision:0.863,acc:0.9658,specificity:0.990\n",
      ":-- jaccard:0.6179, f1:0.7638,recall:0.7136,precision:0.822,acc:0.9609,specificity:0.985\n",
      ":-- jaccard:0.5924, f1:0.7440,recall:0.6345,precision:0.899,acc:0.9625,specificity:0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:00<00:00, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.5987, f1:0.7490,recall:0.6392,precision:0.904,acc:0.9581,specificity:0.993\n",
      ":-- jaccard:0.6107, f1:0.7583,recall:0.6874,precision:0.845,acc:0.9646,specificity:0.989\n",
      ":-- jaccard:0.6279, f1:0.7714,recall:0.7235,precision:0.826,acc:0.9694,specificity:0.988\n",
      ":-- jaccard:0.6209, f1:0.7661,recall:0.6937,precision:0.855,acc:0.9618,specificity:0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-- jaccard:0.5616, f1:0.7193,recall:0.6319,precision:0.835,acc:0.9584,specificity:0.988\n",
      ":-- jaccard:0.6323, f1:0.7747,recall:0.7524,precision:0.798,acc:0.9653,specificity:0.984\n",
      ":-- jaccard:0.6846, f1:0.8128,recall:0.8061,precision:0.819,acc:0.9691,specificity:0.984\n",
      ":-- jaccard:0.6172, f1:0.7633,recall:0.7457,precision:0.782,acc:0.9659,specificity:0.983\n",
      "\n",
      "Overall---Jaccard: 0.6077 - F1: 0.7550 - Sensitivity: 0.6799 - Precision: 0.8579 - Acc: 0.9619 - Specificity:0.9891\n",
      "FPS:  249.49313854371763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import os, time\n",
    "from operator import add\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# from model import build_unet\n",
    "# from utils import create_dir, seeding\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    # 使用混淆矩阵计算 TP, FP, FN, TN\n",
    "    # labels=[0, 1] 确保即使数据中缺少某一类也能返回 2x2 矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    # Dice Coefficient (F1 Score) = 2 * TP / (2 * TP + FP + FN)\n",
    "    score_f1 = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "\n",
    "    # Jaccard (IoU) = TP / (TP + FP + FN)\n",
    "    score_jaccard = tp / (tp + fp + fn + 1e-6)\n",
    "\n",
    "    # Sensitivity (Recall) = TP / (TP + FN)\n",
    "    score_recall = tp / (tp + fn + 1e-6)\n",
    "\n",
    "    # Specificity = TN / (TN + FP)\n",
    "    score_specificity = tn / (tn + fp + 1e-6)\n",
    "\n",
    "    # Precision = TP / (TP + FP)\n",
    "    score_precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    # Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    score_acc = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, score_specificity]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(\"working/results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    test_x = sorted(glob(\"working/new_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"working/new_data/test/mask/*\"))\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 560\n",
    "    W = 560\n",
    "    size = (W, H)\n",
    "    checkpoint_path = \"working/files/drive_checkpoint_loss.pth\"\n",
    "\n",
    "    \"\"\" Load the checkpoint \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "    \n",
    "    # Lists to store metrics for each image for plotting\n",
    "    image_indices = []\n",
    "    jaccard_scores = []\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    specificity_scores = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "        ## image = cv2.resize(image, size)\n",
    "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
    "        x = x/255.0\n",
    "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "        ## mask = cv2.resize(mask, size)\n",
    "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
    "        y = y/255.0\n",
    "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            pred_y = model(x)\n",
    "            pred_y = torch.sigmoid(pred_y)\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            print(f\":-- jaccard:{score[0]:1.4f}, f1:{score[1]:1.4f},recall:{score[2]:1.4f},precision:{score[3]:1.3f},acc:{score[4]:1.4f},specificity:{score[5]:1.3f}\")\n",
    "            \n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            \n",
    "            # Store for plotting\n",
    "            image_indices.append(i)\n",
    "            jaccard_scores.append(score[0])\n",
    "            f1_scores.append(score[1])\n",
    "            recall_scores.append(score[2])\n",
    "            specificity_scores.append(score[5])\n",
    "            \n",
    "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
    "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        pred_y = mask_parse(pred_y)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(f\"working/results/{name}.png\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    spec = metrics_score[5]/len(test_x)\n",
    "    print(f\"\\nOverall---Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Sensitivity: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - Specificity:{spec:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 946814,
     "sourceId": 1604025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pampc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
